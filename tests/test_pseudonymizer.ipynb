{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2238a882",
   "metadata": {},
   "source": [
    "### 가명처리 모듈 파이썬 오픈소스 라이브러리 구현 프로젝트\n",
    "\n",
    "**가명정보**\n",
    "\n",
    "개인정보 일부를 삭제, 대체하는 등 가명처리함으로써 원래 상태로 복원하기 위한 추가정보의 사용, 결합 없이는 특정 개인을 알아볼 수 없는 정보\n",
    "\n",
    "**가명정보 처리**\n",
    "\n",
    "가명처리와 달리 가명정보 처리는 가명정보의 수집, 생성, 연계, 연동, 기록, 저장, 보유, 가공, 편집, 검색, 출력, 정정, 복구, 이용, 제공, 공개, 파기, 그밖에 이와 유사한 행위를 말한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c167c6",
   "metadata": {},
   "source": [
    "**신용정보의 이용에 관한 법률 제2조제15호 및 제16호에 의한 가명정보**\n",
    "\n",
    "15. “가명처리”란 추가정보를 사용하지 아니하고는 특정 개인인 신용정보주체를 알아볼 수 없도록 개인신용정보를 처리(그 처리 결과가 다음 각 목의 어느 하나에 해당하는 경우로서 제40조의2제1항 및 제2항에 따라 그 추가정보를 분리하여 보관하는 등 특정 개인인 신용정보주체를 알아볼 수 없도록 개인신용정보를 처리한 경우를 포함한다)하는 것을 말한다.\n",
    "    \n",
    "가. 어떤 신용정보주체와 **다른 신용정보주체가 구별**되는 경우\n",
    "    \n",
    "나. 하나의 정보집합물(정보를 체계적으로 관리하거나 처리할 목적으로 일정한 규칙에 따라 구성되거나 배열된 둘 이상의 정보들을 말한다. 이하 같다)에서나 서로 다른 둘 이상의 정보집합물 간에서 어떤 신용정보주체에 관한 **둘 이상의 정보가 연계되거나 연동**되는 경우\n",
    "    \n",
    "다. 가목 및 나목과 유사한 경우로서 대통령령으로 정하는 경우\n",
    "    \n",
    "16. “가명정보”란 가명처리한 개인신용정보를 말한다.\n",
    "\n",
    "**개인식별정보와 개인식별가능정보**\n",
    "\n",
    "|  | 식별정보 | 식별가능정보 |\n",
    "| --- | --- | --- |\n",
    "| 정의 | 특정 개인과 직접적으로 연결되는 정보 | 다른 항목과 결합하는 경우 식별가능성이 높아지는 항목 해당 정보를 처리하는 자(이용 또는 제공하는 자)를 기준으로 판단 |\n",
    "| 예시 | 성명, 고유식별정보, 의료기록번호, 건강기록번호, (개인)휴대전화번호, (개인)전자우편주소 등 | 성별, 연령, 거주 지역, 국적, 직업, 위치정보 등 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f09b2e2",
   "metadata": {},
   "source": [
    "https://github.com/ksydata/pseudonymizer/tree/main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84efd01a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0341496d",
   "metadata": {},
   "source": [
    "**가명처리의 5단계 절차**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0a3f3b",
   "metadata": {},
   "source": [
    "1. 목적 설정 등 사전 준비 단계\n",
    "    \n",
    "    개인정보를 가명처리하는 목적을 설정한다. 개인정보 처리방침 및 내부관리계획 등 필요한 기본 서류를 작성한다. 정보주체의 동의 없이 가명처리하기 위해서는 1️⃣ 통계 작성, 2️⃣ 과학적 연구(상업 목적 연구 포함), 3️⃣ 공익적 기록 보존이라는 3가지 목적으로 한정된다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88863eb",
   "metadata": {},
   "source": [
    "2. **위험성 검토 단계**\n",
    "    \n",
    "    가명처리 대상 데이터의 식별 위험성을 분석 · 평가한다. 데이터 식별가능성은 1️⃣ 데이터 자체의 식별 위험성(data, context side)과 2️⃣ 처리 환경의 안전성에 따른 식별 위험성으로 구분된다. \n",
    "    \n",
    "    데이터 자체의 식별 위험성은 1️⃣ 성명 · 고유식별정보 등 데이터 식별성이 일정 수준 이상인지, 2️⃣ 특이정보(희귀 성씨 등)가 포함되어 있는지, 3️⃣ 식별될 경우 사회적 파장이 클 수 있는 정보(유명인의 정보 등)에 대한 종합 결론을 말한다. \n",
    "    \n",
    "    처리 환경의 식별 위험성은 1️⃣ 데이터의 활용 형태(내부 이용 또는 외부 제공), 2️⃣ 처리 장소(다른 정보의 접근이 제한된 장소에서 처리되는지 여부 등),  3️⃣ 처리 방법(가명정보를 다른 정보와 연계하는지 등)을 고려해 판단한다. \n",
    "    \n",
    "    위험성 검토 결과는 보고서로 작성되어 적정성 검토 시 활용된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a363f06e",
   "metadata": {},
   "source": [
    "3. **가명처리 단계**\n",
    "\n",
    "    가명처리 기법과 처리 수준을 결정 · 실행한다. 대표적인 가명처리 기술은 대체 · 삭제 ·  범주화다. 1️⃣ 대체는 개인식별정보를 암호화된 일련번호(해시값)으로 대신한다. 2️⃣ 삭제는 개인정보 전부 또는 일부(행, 열, 로컬 등)를 없애는 것이다. 3️⃣ 범주화는 연속형 변수를 일정 단위로 묶는 것이다. 이외에도 4️⃣ 양쪽 끝에 치우친 정보를 삭제 또는 경계치를 입력하는 상하단 코딩 기법과 프라이버시 보호 모델(KLT 모델)이 주로 활용된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d08dc2",
   "metadata": {},
   "source": [
    "4. 적정성 검토 단계  \n",
    "    \n",
    "    내부 또는 외부 검토위원들은 가명처리 결과의 적적성을 최종 논의한다. 3명 이상의 검토위원이 도출한 최종 검토 결과를 개인정보 처리자에게 전달한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277ba8ef",
   "metadata": {},
   "source": [
    "5. 안전한 관리 단계\n",
    "    \n",
    "    가명정보[개인정보]에 대한 안전성 확보 조치를 이행하고, 처리내역을 기록 ·  보관한다. 특정 개인의 재식별 위험을 모니터링하는 것이 중요하다. 가명정보의 보유기간이 도래하면 지체없이 파기하여야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2d2d019",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "from sqlalchemy import create_engine\n",
    "# pip install mysqlclient\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import *\n",
    "import re\n",
    "\n",
    "from prettytable import PrettyTable\n",
    "import pandas as pd\n",
    "pd.options.display.float_format = '{:.10f}'.format\n",
    "import pprint\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2594c84d",
   "metadata": {},
   "source": [
    "**0.파이썬 스크립트를 통해 MySQL 데이터베이스에 접속하여 테이블을 조회하는 방식**\n",
    "\n",
    "* import ⇢ db접속 ⇢ cursor 생성* ⇢ sql문 작성 ⇢ sql문 실행 ⇢ 실행 결과 확정(commit) ⇢ 연결 해제\n",
    "* 검색해온 데이터를 key:value 타입으로 가지고 오는 pymysul.cursor.Dictionary\n",
    "* insert, update, delete의 경우 자원 닫아주기 전에 commit을 해야 DB에 작업 내용이 저장\n",
    "```\n",
    "CURSOR = PseudonymDB.cursor()\n",
    "SQL = \"\"\"SELECT * FROM DATABASE.TABLE\"\"\"\n",
    "CURSOR.execute(SQL)\n",
    "PseudonymDB.commit()\n",
    "PseudonymDB.close()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87404ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreprocessQuery:\n",
    "    \"\"\"데이터 전처리 목적의 SQL 쿼리 클래스\"\"\"\n",
    "    def __init__(self, pw):\n",
    "        self._pw = pw\n",
    "        self.connection = None\n",
    "        self.Cursor = None\n",
    "        self.SQL = None\n",
    "    \n",
    "    def connectMySQL(self, \n",
    "                     serverIP: str, port_num: int, user_name: str, database_name: str, kr_encoder: str):\n",
    "        \"\"\"MySQL DBMS 데이터베이스에 접속: 서버IP주소, 사용자명, 계정 암호, 데이터베이스명, 한글 인코딩 방식\"\"\"\n",
    "        try:\n",
    "            self.connection = pymysql.connect(\n",
    "                host = serverIP, port = port_num,\n",
    "                user = user_name, password = self._pw,\n",
    "                db = database_name, charset = kr_encoder\n",
    "            )\n",
    "            self.Cursor = self.makeCursor(self.connection)\n",
    "        except pymysql.Error as e:\n",
    "            print(f\"Error Connecting to MySQL from Python: {e}\")\n",
    "    \n",
    "    def makeCursor(self, connect):\n",
    "        \"\"\"커서 생성\"\"\"\n",
    "        return connect.cursor()\n",
    "    \n",
    "    def dataQueryLanguage(self, sql):\n",
    "        \"\"\"SQL 쿼리문 작성\"\"\"\n",
    "        self.SQL = f\"{sql}\"\n",
    "    \n",
    "    def queryExecute(self):\n",
    "        \"\"\"SQL 쿼리문 실행 및 예외처리\"\"\"\n",
    "        try:\n",
    "            self.Cursor.execute(self.SQL)\n",
    "            actionOutput = self.Cursor.fetchall()\n",
    "            return actionOutput\n",
    "        except pymysql.Error as e:\n",
    "            print(f\"Error Executing Query: {e}\")\n",
    "    \n",
    "    def queryCommit(self):\n",
    "        \"\"\"실행 결과 확정\"\"\"\n",
    "        self.Cursor.execute(self.SQL)\n",
    "        self.Cursor.commit()\n",
    "    \n",
    "    def closeConnection(self):\n",
    "        \"\"\"연결 및 커서 닫기\"\"\"\n",
    "        if self.Cursor:\n",
    "            self.Cursor.close()\n",
    "        if self.connection:\n",
    "            self.connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04d11bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "queryObject = PreprocessQuery(pw = \"0123\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ef460b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "queryObject.connectMySQL( \n",
    "    serverIP = \"localhost\", port_num = 3306, user_name = \"root\", database_name = \"FINANCIALCONSUMER\", kr_encoder = \"utf8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6303cfcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL 쿼리문 입력변수 = \n",
      "Error Executing Query: (1065, 'Query was empty')\n"
     ]
    }
   ],
   "source": [
    "SQL = input(\"SQL 쿼리문 입력변수 = \")\n",
    "queryObject.dataQueryLanguage(sql = SQL)\n",
    "results = queryObject.queryExecute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43f6115a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ac9095",
   "metadata": {},
   "outputs": [],
   "source": [
    "DQL = \"\"\"SELECT \n",
    "    SUBSCRIPTION_MONTH,\n",
    "    MEMBERSHIP_GRADE,\n",
    "    SUBSCRIPTION_SALES * 100 / TOTAL_SALES AS PCT_TOTAL_SALES\n",
    "FROM (\n",
    "    SELECT \n",
    "        T1.SUBSCRIPTION_MONTH,\n",
    "        T1.MEMBERSHIP_GRADE,\n",
    "        T1.SUBSCRIPTION_SALES,\n",
    "        SUM(T2.SUBSCRIPTION_SALES) AS TOTAL_SALES\n",
    "    FROM (\n",
    "        SELECT \n",
    "            DATE_FORMAT(STR_TO_DATE(SUBSCRIPTION_DATE, '%Y%m%d'), '%Y-%m') AS SUBSCRIPTION_MONTH,\n",
    "            MEMBERSHIP_GRADE,\n",
    "            SUM(SUBSCRIPTION_FEE) AS SUBSCRIPTION_SALES\n",
    "        FROM \n",
    "            DATA_MOBILE_COMMUNICATION\n",
    "        GROUP BY \n",
    "            SUBSCRIPTION_MONTH, MEMBERSHIP_GRADE\n",
    "    ) AS T1\n",
    "    JOIN (\n",
    "        SELECT \n",
    "            DATE_FORMAT(STR_TO_DATE(SUBSCRIPTION_DATE, '%Y%m%d'), '%Y-%m') AS SUBSCRIPTION_MONTH,\n",
    "            MEMBERSHIP_GRADE,\n",
    "            SUM(SUBSCRIPTION_FEE) AS SUBSCRIPTION_SALES\n",
    "        FROM \n",
    "            DATA_MOBILE_COMMUNICATION\n",
    "        WHERE \n",
    "            MEMBERSHIP_GRADE IN ('VIP', 'VVIP')\n",
    "        GROUP BY \n",
    "            SUBSCRIPTION_MONTH, MEMBERSHIP_GRADE\n",
    "    ) AS T2\n",
    "    ON T1.SUBSCRIPTION_MONTH = T2.SUBSCRIPTION_MONTH\n",
    "    WHERE T1.MEMBERSHIP_GRADE IN ('VIP', 'VVIP')\n",
    "    GROUP BY 1, 2, 3\n",
    ") T3\n",
    "ORDER BY 1, 2;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69dd55c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DQL = input(\"SQL 쿼리문 입력변수 = \")\n",
    "queryObject.dataQueryLanguage(sql = DQL)\n",
    "results = queryObject.queryExecute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfdb036",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "if results:\n",
    "    # PrettyTable에 결과를 추가할 때 각 행의 값이 컬럼 수와 일치해야 함\n",
    "    # ValueError: Row has incorrect number of values, (actual) 5!=1 (expected)\n",
    "    columns = [ [desc[0] for desc in queryObject.Cursor.description] ]\n",
    "    table = PrettyTable(*columns)\n",
    "    \n",
    "    for row in results:\n",
    "        row_list = list(row)\n",
    "        table.add_row(row_list)\n",
    "    print(table)\n",
    "    # ???\n",
    "    # 원인은 DB에 애초에 잘못 저장된 테이블의 가입일자 컬럼에 있었음\n",
    "    # 해결은 모바일 통신서비스 가입일자가 YYYYMMDD 형식이므로 일단 가변문자 타입인 VARCHAR로 선언한 후\n",
    "    # DATE_FORMAT(time, timestamp)으로 형식 변환 등 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f906d4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 월간 전체 (통신서비스 가입) 매출액 대비 멤버십 회원등급별 매출액 비율 시각화  \n",
    "plt.figure(figsize = (50, 10))\n",
    "plt.plot(\n",
    "    pd.DataFrame(results).loc[pd.DataFrame(results)[1] == \"VIP\", 0],\n",
    "    pd.DataFrame(results).loc[pd.DataFrame(results)[1] == \"VIP\", 2],\n",
    "    color = \"green\"\n",
    ")\n",
    "# plt.show()\n",
    "# plt.figure(figsize = (50, 10))\n",
    "plt.plot(\n",
    "    pd.DataFrame(results).loc[pd.DataFrame(results)[1] == \"VVIP\", 0],\n",
    "    pd.DataFrame(results).loc[pd.DataFrame(results)[1] == \"VVIP\", 2],\n",
    "    color = \"orange\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353f281a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49738292",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sooyeon Kang\\AppData\\Local\\Temp\\ipykernel_14964\\3098708441.py:1: SADeprecationWarning: The create_engine.convert_unicode parameter and corresponding dialect-level parameters are deprecated, and will be removed in a future release.  Modern DBAPIs support Python Unicode natively and this parameter is unnecessary.\n",
      "  engine = create_engine(\n"
     ]
    }
   ],
   "source": [
    "engine = create_engine(\n",
    "    \"mysql://root:0123@localhost/FINANCIALCONSUMER\", \n",
    "    convert_unicode = True)\n",
    "conn = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ff13575",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FINANCE = pd.read_sql_table(\"DATA_FINANCE\", conn)\n",
    "DATA_RETAIL = pd.read_sql_table(\"DATA_RETAIL\", conn)\n",
    "DATA_MOBILE_COMMUNICATION = pd.read_sql_table(\"DATA_MOBILE_COMMUNICATION\", conn)\n",
    "DATA_JOIN_CARDPAYMENT = pd.read_sql_table(\"DATA_JOIN_CARDPAYMENT\", conn)\n",
    "DATA_JOIN_ACCOMODATIONAPP = pd.read_sql_table(\"DATA_JOIN_ACCOMODATIONAPP\", conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0718a95c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4a654e",
   "metadata": {},
   "source": [
    "1. 구현의 핵심 목표는 **가명처리 패키지를 구조화하고 필요한 기능을 제공하기 위해 디렉토리 구조와 객체 및 속성을 설계**함에 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bae254e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ./pseudonymizer/\n",
    "\n",
    "class Pseudonymizer(ABC):\n",
    "    \"\"\"가명처리 추상 클래스 및 추상 메서드 선언\"\"\"\n",
    "    @abstractmethod\n",
    "    def pseudonymizeData(self, value):\n",
    "        \"\"\"확장성을 갖춘 가명처리 클래스를 만들어 특정 가명처리 기법으로 구체화하기 위한 추상 메서드\"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c2dd8e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e9ba5d",
   "metadata": {},
   "source": [
    "2. **MaskingPseudonymizer | 마스킹 적용(정규표현식을 주로 활용)**\n",
    "\n",
    "* 성명: 직접 식별자에 대해 마스킹을 적용하여 식별성을 낮출 수 있음. 단, 이름이 세글자가 아닌 경우에는 어떻게 할지(두글자이거나 네글자 이상일 경우. 한국인이 아닌 외국인일 경우 어떻게 처리할지)\n",
    "\n",
    "* 나이 : 간접 식별자에 대해 마스킹을 적용할 수는 있지만 마스킹 방식을 거의 사용하지 않음\n",
    "\n",
    "* 질병코드 : 민감 질병에 대해 마스킹을 적용하여 식별성을 낮춘 사례\n",
    "\n",
    "* 사업자 등록번호 :\n",
    "\n",
    "    (1) 법인의 종류를 알 수 없도록 가운데 마스킹(2자릿수)\n",
    "    \n",
    "    (2) 법인의 종류만 구분가능하도록 맨 마지막 마스킹(5자릿수)\n",
    "    \n",
    "* 이메일 주소 : 메일발신기관만 구분가능하도록 마스킹하거나 발신자와 발신기관 모두 구분할 수 없도록 마스킹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e63aeb",
   "metadata": {},
   "source": [
    "* 특수문자 체크 정규식\n",
    "  const regExp = /[\\{\\}\\[\\]\\/?.,;:|\\)*~`!^\\-_+<>@\\#$%&\\\\\\=\\(\\'\\\"]/g;\n",
    "\n",
    "* 모든 공백 체크 정규식\n",
    "  const regExp = /\\s/g;\n",
    "\n",
    "* 숫자만 체크 정규식\n",
    "  const regExp = /[0-9]/g;\n",
    "\n",
    "* 이메일 체크 정규식\n",
    "  const regExp = /^[0-9a-zA-Z]([-_\\.]?[0-9a-zA-Z])*@[0-9a-zA-Z]([-_\\.]?[0-9a-zA-Z])*\\.[a-zA-Z]{2,3}$/i;\n",
    "  \n",
    "* 핸드폰번호 정규식\n",
    "  const regExp = /^\\d{3}-\\d{3,4}-\\d{4}$/;\n",
    "\n",
    "* 일반 전화번호 정규식\n",
    "  const regExp = /^\\d{2,3}-\\d{3,4}-\\d{4}$/;\n",
    "\n",
    "* 아이디나 비밀번호 정규식\n",
    "  const regExp = /^[a-z0-9_]{4,20}$/;\n",
    "\n",
    "* 휴대폰번호 체크 정규식\n",
    "  const regExp = /^01([0|1|6|7|8|9]?)-?([0-9]{3,4})-?([0-9]{4})$/;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53c0138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ./pseudonymizer/pseudonymizers/nameMasking.py\n",
    "\n",
    "# from pseudonymizer.pseudonymizer import Pseudonymizer\n",
    "\n",
    "class NameMaskingModule(Pseudonymizer):\n",
    "    \"\"\"\n",
    "    성명 마스킹 클래스\n",
    "    ------------------\n",
    "    성명 식별자에 직접 마스킹을 적용하여 식별성을 낮추는 구체 클래스\n",
    "    3자릿수가 넘는 이름은 특정인에 대한 식별가능성이 높아지므로 4자릿수로 마스킹\n",
    "    \"\"\"\n",
    "    def pseudonymizeData(self, name):\n",
    "        name_list = list(name)\n",
    "        if 2 <= len(name) <= 3:\n",
    "            return name_list[0] + \"*\"*(len(name)-1)\n",
    "        else: \n",
    "            # len(name) > 4:\n",
    "            return name_list[0] + \"*\"*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957cccfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ./pseudonymizer/pseudonymizers/emailMasking.py\n",
    "\n",
    "# from pseudonymizer.pseudonymizer import Pseudonymizer\n",
    "# import re\n",
    "# from typing import *\n",
    "\n",
    "class EmailMaskingModule(Pseudonymizer):\n",
    "    \"\"\"\n",
    "    이메일 마스킹 클래스\n",
    "    --------------------\n",
    "    이메일 주소의 메일 발신자 또는 발신기관을 구분할 수 없도록 하는 구체 클래스\n",
    "    \"\"\"\n",
    "    def __init__(self, masking_domain: bool):\n",
    "        self.masking_domain = masking_domain\n",
    "        \n",
    "    def pseudonymizeData(self, email):\n",
    "        pattern_match = re.match(\n",
    "            r\"^[a-zA-z0-9]([-_\\.]?[a-zA-Z0-9])*@[a-zA-Z0-9]+\\(.[a-zA-Z]{2,3})\", email)\n",
    "            # .: 정확히 1개 문자 매칭\n",
    "            # * : 앞 패턴이 0개 이상이어야 함\n",
    "            # ? : 앞 패턴이 없거나 하나이어야 함\n",
    "            # + : 1회 이상 반복되는 패턴을 매칭\n",
    "            # \\. : 도메인과 최상위 도메인(TLD)에 대한 구분자 마침표 \n",
    "            # {,} : 중괄호 안에 표기된 범위만큼 반복되는 패턴을 매칭. {3,5}는 3~5회 매칭을 의미함\n",
    "            \n",
    "        if pattern_match:\n",
    "            local_part = pattern_match.group(0)\n",
    "            domain_part = pattern_match.group(1)\n",
    "            tld_part = pattern_math.group(2)\n",
    "            # local_part, domain_part = email.split(\"@\")\n",
    "            \n",
    "            if self.masking_domain:\n",
    "                masked_local_part = re.sub(r\"\\S\", \"*\", local_part)\n",
    "                masked_domain_part = re.sub(r\"\\S\", \"*\", domain_part)\n",
    "                return masked_local_part + \"@\" + masked_domain_part + tld_part\n",
    "            else:\n",
    "              # self.masking_domain = False:\n",
    "                masked_local_part = re.sub(r\"\\S\", \"*\", local_part)\n",
    "                return masked_local_part + \"@\" + domain_part + tld_part\n",
    "\n",
    "        else:\n",
    "            print(\"입력받은 { }은 이메일 패턴에 매칭되지 않아 마스킹할 수 없습니다.\".format(email))\n",
    "    \n",
    "        # 이메일의 표준은 인터넷 표준 기구(IETF, Internet Engineering Task Force)에서 정의\n",
    "        # re.sub(pattern, replace, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511e3b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ./pseudonymizer/pseudonymizers/residentNumMasking.py\n",
    "\n",
    "# from pseudonymizer.pseudonymizer import Pseudonymizer\n",
    "\n",
    "class ResidentNumberMaskingModule(Pseudonymizer):\n",
    "    \"\"\"\n",
    "    주민등록번호 마스킹 클래스\n",
    "    --------------------\n",
    "    주민등록번호 뒷자리를 복원할 수 없는 비가역성 기법으로 개인의 식별을 방지하는 구체 클래스\n",
    "    \"\"\"        \n",
    "    def pseudonymizeData(self, resident_number):\n",
    "        \"\"\"한국 주민등록번호의 정규표현식을 기준으로 패턴 매칭이 되는 경우 뒷자리 7자리 중 \n",
    "        성별정보 1자리를 제외한 나머지 출생지정보에 대한 6자리에 대한 마스킹을 수행하는 메서드\"\"\"\n",
    "        pattern_match = re.match(r\"^\\d{6}-[1-8]\\d{6}$\", resident_number)\n",
    "        \n",
    "        if pattern_match:\n",
    "            front_part, rear_part = resident_number.split(\"-\")\n",
    "            return front_part + rear_part[0] + \"*\"*6\n",
    "            \n",
    "        else:\n",
    "            print(\"입력받은 { }은 주민등록번호 패턴에 매칭되지 않아 마스킹할 수 없습니다.\".format(resident_number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e08f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ./pseudonymizer/pseudonymizers/businessMasking.py\n",
    "\n",
    "# from pseudonymizer.pseudonymizer import Pseudonymizer\n",
    "# from typing import *\n",
    "\n",
    "class BusinessNumberMaskingModule(Pseudonymizer):\n",
    "    \"\"\"\n",
    "    사업자등록번호 마스킹 클래스\n",
    "    --------------------\n",
    "    사업자등록번호의 일부(2번째 혹은 3번째 자리)를 복원할 수 없는 비가역성 기법으로 개인의 식별을 방지하는 구체 클래스\n",
    "    \"\"\"\n",
    "    def __init__(self, masking_part: str):\n",
    "        self.masking_part = masking_part\n",
    "        \n",
    "    def pseudonymizeData(self, business_number):\n",
    "        \"\"\"한국 사업자등록번호의 정규표현식을 기준으로 패턴 매칭이 되는 경우 마스킹을 수행하는 메서드\"\"\"\n",
    "        pattern_match = re.match(r\"^\\d{3}-\\d{2}-\\d{5}$\", business_number)\n",
    "        # ex) 124-86-23875\n",
    "        \n",
    "        if pattern_match:\n",
    "            front_part, middle_part, rear_part = business_number.split(\"-\")\n",
    "            \n",
    "           # 2번째 자리인 법인의 등록지역을 마스킹할 때\n",
    "            if self.masking_part == \"middle\":\n",
    "                return front_part + \"*\"*2 + rear_part\n",
    "           # 3번째 자리인 법인의 일련번호를 마스킹할 때\n",
    "            elif self.masking_part == \"rear\":\n",
    "                return front_part + middle_part + \"*\"*5\n",
    "           # 1번째 자리인 법인의 유형만을 남기고 마스킹할 때\n",
    "            elif self.masking_part == \"both\":\n",
    "                return front_part + \"*\"*2 + \"-\" + \"*\"*5\n",
    "        else:\n",
    "            print(\"입력받은 { }은 사업자등록번호 패턴에 매칭되지 않아 마스킹할 수 없습니다.\".format(business_number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6169e773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ./pseudonymizer/pseudonymizers/businessMasking.py\n",
    "\n",
    "# from pseudonymizer.pseudonymizer import Pseudonymizer\n",
    "# from typing import *\n",
    "\n",
    "class AddressMaskingModule(Pseudonymizer):\n",
    "    \"\"\"\n",
    "    주소 마스킹 클래스\n",
    "    --------------------\n",
    "    시군구 읍면동 단위의 일부를 복원할 수 없는 비가역성 기법으로 제거하는 구체 클래스\n",
    "    \"\"\"\n",
    "    def __init__(self, masking_loca: str):\n",
    "        self.masking_loca = masking_loca\n",
    "        \n",
    "    def pseudonymizeData(self, address: str):\n",
    "        \"\"\"주소의 일부에 대한 마스킹을 수행하는 메서드\"\"\"    \n",
    "        # 시군구 단위\n",
    "        if self.masking_loca == \"시군구\":\n",
    "            return \n",
    "        # 시군구 읍면동/행정동 단위\n",
    "        elif self.masking_part == \"읍면동\":\n",
    "            return \n",
    "        else:\n",
    "            print(\"입력받은 { }은 주소가 아닙니다.\".format(address))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b429bf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ./pseudonymizer/pseudonymizers/phoneNumMasking.py\n",
    "\n",
    "# from pseudonymizer.pseudonymizer import Pseudonymizer\n",
    "# from typing import *\n",
    "\n",
    "class PhoneNumberMaskingModule(Pseudonymizer):\n",
    "    \"\"\"\n",
    "    연락처(휴대전화번호 혹은 일반전화번호) 마스킹 클래스\n",
    "    --------------------\n",
    "    3번째 자리를 복원할 수 없는 비가역성 기법으로 개인의 식별을 방지하는 구체 클래스\n",
    "    특히 연관된 다른 정보(생년월일, 기념일, 가족 전화번호, 기존 통화내역 등)와 쉽게 결합하여 사용자가 누구인지 식별가능하다는 점에서 개인정보에 해당함\n",
    "    \"\"\"   \n",
    "    def pseudonymizeData(self, phone_number):\n",
    "        \"\"\"전화번호의 정규표현식을 기준으로 패턴 매칭이 되는 경우 마스킹을 수행하는 메서드\"\"\"\n",
    "        pattern_match = re.match(r\"^\\[0-9]-\\[0-9]-\\d{4}$\", phone_number)\n",
    "        \n",
    "        if pattern_match:\n",
    "            front_part, middle_part, rear_part = phone_number.split(\"-\")\n",
    "            return front_part + middle_part + \"*\"*4\n",
    "        # 다만, 전화번호 마지막 4자리는 ****와 같은 기호로 대체하지 않고 전체를 해시값으로 암호화하기도 한다는 점에 유의하여야 함\n",
    "        # 암호화와 복호화는 알고리즘 및 키 관리 등 복잡한 과정이 필요하므로 높은 보안이 필요한 경우 고려함\n",
    "        else:\n",
    "            print(\"입력받은 { }은 전화번호 패턴에 매칭되지 않아 마스킹할 수 없습니다.\".format(phone_number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512ca72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ./pseudonymizer/pseudonymizers/maskingPseudonymizer.py\n",
    "\n",
    "# from pseudonymizer.pseudonymizers.nameMasking import NameMaskingModule\n",
    "# from pseudonymizer.pseudonymizers.emailMasking import EmailMaskingModule\n",
    "# from pseudonymizer.pseudonymizers.residentNumMasking import ResidentNumberMaskingModule\n",
    "# from pseudonymizer.pseudonymizers.businessNumMasking import BusinessNumberMaskingModule\n",
    "# from pseudonymizer.pseudonymizers.phoneNumMasking import PhoneNumberMaskingModule\n",
    "\n",
    "# import re\n",
    "# from typing import *\n",
    "\n",
    "    \n",
    "class MaskingPseudonymizer(Pseudonymizer):\n",
    "    def __init__(self, data_type: str, masking_domain: bool, masking_part: str):\n",
    "        \"\"\"data_type은 향후 pseudonymizer.py에서 Pseudonymn 실행 클래스의 \n",
    "        self._dataframe[column] 개인식별정보의 유형으로 이름, 이메일, 주민등록번호, 사업자등록번호 중 하나로 선언\"\"\"\n",
    "        self.data_type = datatype,\n",
    "        self.email_masker = EmailMaskingModule(masking_domain)\n",
    "        self.name_masker = NameMaskingModule()\n",
    "        self.resident_num_masker = ResidentNumberMaskingModule()\n",
    "        self.business_num_masker = BusinessNumberMaskingModule(masking_part)\n",
    "        self.phone_num_masker = PhoneNumberMaskingModule()\n",
    "\n",
    "    def pseudonymizeData(self, data):\n",
    "        if data_type == \"name\":\n",
    "            return self.name_masker.pseudonymzieData(data)\n",
    "        elif data_type == \"email\":\n",
    "            return self.email_masker.pseudonymzieData(data)\n",
    "        elif data_type == \"resident_number\":\n",
    "            return self.resident_num_masker.pseudonymizeData(data)\n",
    "        elif data_type == \"business_number\":\n",
    "            return self.business_num_masker.pseudonymizeData(data)\n",
    "        elif data_type == \"phone_number\":\n",
    "            return self.phone_num_masker.pseudonymizeData(data)\n",
    "        else:\n",
    "            raise ValueError(\"유효한 마스킹 대상 개인식별정보 데이터 타입이 아닙니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81879928",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36db502",
   "metadata": {},
   "source": [
    "3. **RoundingPseudonymizer**\n",
    "* 일반라운딩은 np.round()함수로 처리가능하므로 구현의 의미 없으므로 제외하며,\n",
    "* 제어라운딩은 라운딩 적용 전후의 항목 합계를 일치시키면서 소요되는 높은 연산량으로 실무에서 활용하지 않으므로 제외\n",
    "* 랜덤라운딩만 구현할 예정\n",
    "* 나이, 신장, 소득, 카드지출금액, 유동인구, 사용자 수 등에 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d87f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ./pseudonymizer/pseudonymizers/randomRoundingPseudonymizer.py\n",
    "\n",
    "# from pseudonymizer.pseudonymizer import Pseudonymizer\n",
    "# from typing import *\n",
    "\n",
    "class RandomRoundingPseudonymizer(Pseudonymizer):\n",
    "    \"\"\"\n",
    "    랜덤라운딩 구체 클래스\n",
    "    ----------------------\n",
    "    데이터의 길이가 일정하지 않은 경우 값의 크기에 따라 처리 단위를 다르게 올림, 내림, 반올림하는 가명처리 기법\n",
    "    \"\"\"\n",
    "    def __init__(self, rounding_type):\n",
    "        self.rounding_type = rounding_type\n",
    "        \n",
    "    def pseudonymizeData(self, numeric):\n",
    "        \"\"\"수치데이터를 실제 수 기준으로 자릿수 올림 또는 내림하여 일반화(범주화)하는 메서드\"\"\"\n",
    "        if self.rounding_type == \"round_up\":\n",
    "            return numeric if numeric == int(numeric) else int(numeric)+1\n",
    "        elif self.rounding_type == \"round_down\":\n",
    "            return int(numeric)\n",
    "        elif self.rounding_type == \"round\":\n",
    "            decimal_part = numeric - int(numeric)\n",
    "            return int(numeric)+1 if decimal_part >= 0.5 else int(numeric)\n",
    "        else:\n",
    "            raise ValueError(\"입력받은 {}은 유효한 라운딩 방법이 아닙니다.\".format(rounding_type))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1b3885",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8615200",
   "metadata": {},
   "source": [
    "4. **PrivacyPreservingModel | 동질 집합(Equivalent class) 찾기와 프라이버시 보호 모델에 따른 PPDM(Privacy Preserving Data Mining)**\n",
    "\n",
    "* 데이터 비식별화 : 식별방지(식별자 제거) 및 추론방지(프라이버시 모델 준수)\n",
    "* 범주화: 연속형 변수를 일정 단위로 묶는 것\n",
    "* 프라이버시 보호 모델(KLT 모델)을 주로 활용하여 개인식별가능정보의 동질성 집합(QI)에 대한 비식별조치를 수행하는 것(K-익명성, L-다양성, T-근접성)\n",
    "* 출처: 박준범 외 2인, 관계형 데이터베이스에서 데이터 그룹화를 이용한 익명화 처리 기법, 한국전자통신연구원 25권 3호, 2015.6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e503fdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ./pseudonymizer/pseudonymizer/deidentificationTechnique/equivalent_class.py\n",
    "\n",
    "class EquivalentClass:\n",
    "    \"\"\"개인식별가능정보 속성을 기준으로 데이터를 그룹화하는 부모 클래스\n",
    "    \n",
    "    준식별자를 이용한 그룹화 기법 의사코드\n",
    "    --------------------------------------\n",
    "    data grouping using quasi-identifier\n",
    "    Input : PI(Personal Information)\n",
    "    Output : Grouped PI\n",
    "\n",
    "    grouped_PI = dict()\n",
    "    for identifier, quasi in PI.items():\n",
    "        key = quasi[0] + quasi[1] + quasi[2] + quasi[3]\n",
    "        if key in grouping_PI:\n",
    "            grouping_PI[key].append(identifier)\n",
    "        else:\n",
    "            grouping_PI[key] = []\n",
    "            grouping_PI[key].append[identifier]\n",
    "\n",
    "        return grouping_PI\n",
    "    \"\"\"\n",
    "    def __init__(self, dataframe):\n",
    "        self._dataframe = dataframe\n",
    "        self.equivalent_class = {}\n",
    "\n",
    "    def __str__(self):\n",
    "        # __repr__\n",
    "        \"\"\"캡슐화된 데이터셋의 속성(컬럼)정보를 반환하는 메서드\"\"\"\n",
    "        return self._dataframe.info()\n",
    "    \n",
    "    def categorizeEquivalentClass(self, attributes: List[str]):\n",
    "        \"\"\"각 행(레코드)에 대한 개인식별가능정보 속성(컬럼)들 사이에 동질 집합을 확인하는 메서드\"\"\"\n",
    "        groupby_data = self._dataframe.groupby(attributes)\n",
    "        \n",
    "        for group, data in groupby_data:\n",
    "            if len(group) > 1:\n",
    "                key = tuple(group)\n",
    "                # 딕셔너리에서 키 값으로 리스트(동적 타입)는 사용할 수 없으므로 튜플로 변환\n",
    "                self.equivalent_class[key] = data.index.tolist()\n",
    "                # 동질 집합에 해당하는 행(레코드)의 인덱스 번호를 키 값으로 조회되도록 저장\n",
    "\n",
    "    def removeDuplicatesInEquivalentClass(self):\n",
    "        \"\"\"각 동질집합 내 레코드 간 중복된 행을 제거하는 메서드\"\"\"\n",
    "        for group_key, index_value in self.equivalent_class.items():\n",
    "            unique_record = self._dataframe.loc[index_value, :].drop_duplicates()\n",
    "            # set(self._dataframe.loc[index_value, :])\n",
    "            self.equivalent_class[group_key] = unique_records.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744c9eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ./pseudonymizer/pseudonymizer/deidentificationTechnique/kAnonimity.py\n",
    "\n",
    "# from pseudonymizer.pseudonymizer.deidentificationTechnique.equivalent_class import EquivalentClass\n",
    "# from typing import *\n",
    "\n",
    "class K_Anonymity(EquivalentClass):\n",
    "    \"\"\"개별 레코드가 최소한 K개 이상 동일한 속성값을 가지도록 하는 K-익명성 클래스\n",
    "    \n",
    "    데이터 그룹화가 적용된 k-익명성 알고리즘 의사코드\n",
    "    -------------------------------------------------\n",
    "    basic k-anonymity algorithm\n",
    "    Input : grouped_PI, limited_k\n",
    "    Output : k_data\n",
    "    \n",
    "    k_data = dict()\n",
    "    for key, identifiers in grouped_PI.items():\n",
    "        k_anonymity = len(identifiers)\n",
    "        if k_anonymity >= limited_k:\n",
    "            k_data[k] = identifiers\n",
    "    return k_data\n",
    "    \"\"\"\n",
    "    def __init__(self, dataframe):\n",
    "        super().__init__(dataframe)\n",
    "        self.K_data = None\n",
    "        \n",
    "    def applyKAnonymity(self, K: int, attributes: List[str]) -> Dict:\n",
    "        K_data = dict()\n",
    "        # EquivalentClass 클래스의 categorizeEquivalentClass 메서드 호출\n",
    "        super().categorizeEquivalentClass(attributes)\n",
    "\n",
    "        for group_key, index_value in self.equivalent_class.items():\n",
    "            K_anonymity = len(index_value)\n",
    "            # index_value = identifiers\n",
    "            if K_anonymity >= K:\n",
    "                K_data[group_key] = index_value\n",
    "            else:\n",
    "                print(group_key, len(index_value))\n",
    "        self.K_data = K_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000b83dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K_DATA_FINANCE = K_Anonymity(dataframe = DATA_FINANCE)\n",
    "# K_DATA_FINANCE.applyKAnonymity(K = 250, attributes = [\"AGE\", \"TF_PENSION\"])\n",
    "# K_DATA_FINANCE.K_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c97ab17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ./pseudonymizer/pseudonymizer/deidentificationTechnique/lDiversity.py\n",
    "\n",
    "# from pseudonymizer.pseudonymizer.deidentificationTechnique.equivalent_class import EquivalentClass\n",
    "# from typing import *\n",
    "\n",
    "class L_Diversity(K_Anonymity):\n",
    "    \"\"\"각 동질집합 내 특정 민감 속성의 빈도가 L값 이상의 다양성을 가지도록 하는 L-다양성 클래스\n",
    "    k-익명성 보호 모델 적용 결과에 l-다양성 보호 모델을 적용\n",
    "    \n",
    "    k-익명성 처리가 그룹 단위로 구현된 상황에서 l-다양성 알고리즘 의사코드\n",
    "    ----------------------------------------------------------------------\n",
    "    basic l-diversity algorithm\n",
    "    Input : k_data, limited_l\n",
    "    Output : l_data\n",
    "    \n",
    "    l_data = dict()\n",
    "    for key, identifiers in k_data.items():\n",
    "        l_list = []\n",
    "        for identifier in identifiers:\n",
    "            # k익명성을 만족하는 데이터의 식별자값을 가지고 \n",
    "            user_info = data[identifier]\n",
    "            # 해당 식별자값의 민감정보를 가져오는 부분\n",
    "            user_sa = user_info[4]\n",
    "            if user_sa in l_list:\n",
    "                pass\n",
    "    \"\"\"\n",
    "    def __init__(self, dataframe):\n",
    "        \"\"\"모듈의 유연성을 제공하기 위해 K익명성 클래스를 확장하여 손자 클래스로 정의\"\"\"\n",
    "        super().__init__(dataframe)\n",
    "        self.L_data = None\n",
    "        self.sensitive_attribute = None\n",
    "        self.LocalL_data = None\n",
    "        \n",
    "    def applyLDiversity(self, K: int, L: int, attributes: List[str], sensitive_attribute: str):\n",
    "        \"\"\"두 모형을 동시에 적용할 경우 중복이 발생할 가능성이 높아 조합적인 보호 모델을 설계하여 중복을 최소화하는 메서드\"\"\"\n",
    "        super().applyKAnonymity(K, attributes)\n",
    "        L_data = dict()\n",
    "        self.sensitive_attribute = sensitive_attribute\n",
    "        \n",
    "        for group_key, index_value in self.K_data.items():\n",
    "            unique_sensitive_values = self._dataframe.loc[index_value, \n",
    "                                                          sensitive_attribute].unique()\n",
    "            # self._dataframe.iloc[index_value, self._dataframe.columns.get_loc(column_name)]\n",
    "            if len(unique_sensitive_values) >= L:\n",
    "                L_data[group_key] = index_value\n",
    "            else:\n",
    "                print(group_key, len(unique_sensitive_values))\n",
    "        self.L_data = L_data\n",
    "    \n",
    "    def applyLocalLDiversity(self, local_L: int):\n",
    "        \"\"\"특정 민감정보의 속성값이 일부 레코드(행)에 집중되는 문제에 따라\n",
    "        전체적으로 안전한 다양성을 확보할 수 있도록 l-로컬 다양성을 적용하는 메서드\"\"\"\n",
    "        LocalL_data = dict()\n",
    "        \n",
    "        for group_key, index_value in self.L_data.items():\n",
    "            count_local_diversity = self._dataframe.loc[index_value, self.sensitive_attribute].value_counts()\n",
    "            if count_local_diversity.min() >= local_L: \n",
    "                LocalL_data[group_key] = index_value\n",
    "            else:\n",
    "                for sensitive_attr, freq in count_local_diversity.items():\n",
    "                    if freq == count_local_diversity.min():\n",
    "                        print(group_key, sensitive_attr, freq)\n",
    "                    else:\n",
    "                        pass\n",
    "        self.LocalL_data = LocalL_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b748b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# L_DATA_FINANCE = L_Diversity(dataframe = DATA_FINANCE)\n",
    "# L_DATA_FINANCE.applyLDiversity(K = 5, L = 8, attributes = [\"AGE\", \"TF_PENSION\", \"TF_LOAN\"], sensitive_attribute = \"HOME_TYPE\")\n",
    "# L_DATA_FINANCE.applyLocalLDiversity(local_L = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759ec52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counter(DATA_FINANCE.loc[L_DATA.get((23, 'N', 'N')), \"HOME_TYPE\"])\n",
    "# DATA_FINANCE.loc[L_DATA.get((50, 'Y', 'Y')), \"HOME_TYPE\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69370cc",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "raw",
   "id": "25b294f5",
   "metadata": {},
   "source": [
    "# SAMPLE CODE\n",
    "    def t_closeness_check(self, sensitive_attribute: str, target_distribution: Dict[str, float], threshold: float) -> bool:\n",
    "        \"\"\"t-근접성\"\"\"\n",
    "        sensitive_distribution = self._dataframe[sensitive_attribute].value_counts(normalize=True).to_dict()\n",
    "        for value, target_prob in target_distribution.items():\n",
    "            if value in sensitive_distribution:\n",
    "                diff = abs(target_prob - sensitive_distribution[value])\n",
    "                if diff > threshold:\n",
    "                    return False\n",
    "            else:\n",
    "                return False\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5eaad42",
   "metadata": {},
   "source": [
    "**4.1. 전체 집단과 동질 집합의 경험분포 계산: 연속형 변수, 범주형 변수**\n",
    "\n",
    "X 벡터의 empirical pdf(경험분포의 누적확률밀도함수) = P,\n",
    "Y 벡터의 empirical pdf(경험분포의 누적확률밀도함수) = Q\n",
    "$P = [p_1, p_2, \\dots, p_m],\\ Q = [q_1, q_2, \\dots, q_m]$\n",
    "\n",
    "**4.2. 두 민감정보 확률분포의 차이: EMD(토지이동거리)**\n",
    "\n",
    "민감정보 타입이 연속형이라면, \n",
    "$EMD(P, Q) = \\frac{1}{m-1} \\Sigma_{i}^{m-1} |\\Sigma_{j=1}^{i}(q_j - p_j)|$\n",
    "\n",
    "민감정보 타입이 범주형이라면, \n",
    "$E'(P, Q) = \\frac{1}{2} \\Sigma_{i}^{m} |p_i - q_i)|$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ea0bed",
   "metadata": {},
   "source": [
    "범주형 변수의 경우:\n",
    "\n",
    "범주형 변수의 경우, 각 카테고리의 빈도를 기록하여 분포를 표현합니다.\n",
    "이 경우, 각 카테고리 간의 이동 거리는 단순히 카테고리 간의 거리로 정의됩니다.\n",
    "각 카테고리의 확률 분포를 계산한 후, EMD를 계산할 수 있습니다.\n",
    "\n",
    "연속형 변수의 경우, 주어진 데이터를 히스토그램이나 누적 분포 함수로 변환하여 분포를 표현할 수 있습니다.\n",
    "이 경우, 누적 분포 함수를 사용하여 누적 확률 분포를 계산한 후, EMD를 계산할 수 있습니다.\n",
    "다음은 범주형 변수와 연속형 변수 각각에 대한 EMD를 계산하는 과정을 예시로 설명한 것입니다.\n",
    "\n",
    "범주형 변수의 EMD 계산:\n",
    "범주형 변수의 카테고리와 해당 카테고리의 빈도를 파악합니다.\n",
    "각 카테고리의 빈도를 확률 분포로 변환합니다.\n",
    "변환된 확률 분포를 사용하여 EMD를 계산합니다.\n",
    "\n",
    "연속형 변수의 EMD 계산:\n",
    "연속형 변수의 데이터를 히스토그램으로 변환하거나 누적 분포 함수로 변환합니다.\n",
    "변환된 히스토그램 또는 누적 분포 함수를 사용하여 EMD를 계산합니다.\n",
    "이러한 과정을 통해 각 변수 유형에 따라 적절한 방법으로 EMD를 계산할 수 있습니다. 변수의 유형을 고려하여 데이터를 준비하고 EMD를 계산하는 것이 중요합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70fa280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ./pseudonymizer/pseudonymizer/deidentificationTechnique/tCloseness.py\n",
    "\n",
    "# from pseudonymizer.pseudonymizer.deidentificationTechnique.equivalent_class import EquivalentClass\n",
    "\n",
    "# from typing import *\n",
    "# from scipy.stats import wasserstein_distance\n",
    "\n",
    "class T_Closeness(EquivalentClass):\n",
    "    \"\"\"민감 정보(SA)의 분포를 전체 데이터 셋의 분포와 유사하도록 하는 T-근접성 클래스\n",
    "    \n",
    "    l-다양성과 달리 민감정보를 원본 그대로 배열에 저장한 후 \n",
    "    데이터를 내림차순 정렬하여 (확률분포의 차이)\n",
    "    데이터의 분포도를 측정하는 t-근접성 알고리즘 의사코드\n",
    "    -----------------------------------------------------\n",
    "    basic Earth Mover's Distance algorithms\n",
    "    Input : t_list\n",
    "    Output : EMD\n",
    "    \n",
    "    total_range = []\n",
    "    for n in range(100):\n",
    "        total_range.append(n)\n",
    "        # 설정된 배열에 정수가 순서대로 추가\n",
    "        total_length = len(total_info)\n",
    "        \n",
    "        static_part = total_length / len(t_list)\n",
    "        # EMD(데이터의 분산 정도)를 계산하기 위해 나눗셈\n",
    "        extra_part = float(static_part) % float(len(t_list))\n",
    "        extra_part = extra_part.split(\".\")[0]\n",
    "        # 나누어 떨어지지 않는 여분으로 연산해주어야 할 때 계산\n",
    "\n",
    "        balance_value = len(t_list) - (extra_part)\n",
    "        # 데이터의 분산도 측정\n",
    "        # 여분의 연산으로 하는 부분(나누어 떨어지지 않는 수)에 대하여\n",
    "        # 배열의 마지막 부분에서 처리\n",
    "    \"\"\"\n",
    "    def __init__(self, dataframe):\n",
    "        super().__init__(dataframe)\n",
    "        self.T_data = None\n",
    "        self.sensitive_attribute = None\n",
    "        self.tolerance = None\n",
    "        \n",
    "    def checkSensitivesDistribution(self, data_set, sensitive_attribute: str):\n",
    "        \"\"\"개인식별가능정보(준식별자)의 모든 가능한 조합 n개의 관심 대상값\n",
    "        (sensitive_attribute)의 분포와 전체 집단의 분포의 거리 최댓값이 <= t로 규정할 때\n",
    "        분포를 계산하는 메서드\"\"\"\n",
    "        sensitive_vector = data_set[sensitive_attribute]\n",
    "        \n",
    "        # 민감속성의 고유한 값과 그 값의 비율 {v: count/len(V)}\n",
    "        if sensitive_vector.dtype in [\"int\", \"float\"]:\n",
    "            ordered_vector = np.sort(sensitive_vector)\n",
    "            distribution = {v: n/len(ordered_vector)  for (v, n)\n",
    "                            in zip(ordered_vector, list(range(len(ordered_vector))))}\n",
    "        elif sensitive_vector.dtype == \"object\":\n",
    "            distribution = {v: count/len(v) for (v, count) \n",
    "                            in Counter(sensitive_vector).items()}\n",
    "        elif sensitive_vector.dtype == \"category\":\n",
    "            distribution = {v: count/len(v) for (v, count) \n",
    "                            in Counter(sensitive_vector).items()}\n",
    "        else: ValueError(\"입력받은 {}은 유효한 자료형이 아닙니다.\".format(\n",
    "            data_set[self.sensitive_attribute].dtype))\n",
    "        return distribution\n",
    "    \n",
    "    def earthMoversDistance(self, qi_dist, total_dist):\n",
    "        \"\"\"scipy.wasserstein_distance(data_sensitivity, data_population)\"\"\"\n",
    "        # eucdistance = np.sqrt((qi_dist - total_dist)**2)\n",
    "        emdistance = np.sum(np.abs(qi_dist - total_dist))\n",
    "        return emdistance\n",
    "\n",
    "    def applyTCloseness(self, quasi_identifiers: List[str], tolerance: float, sensitive_attribute: str):\n",
    "        \"\"\"tolerance: 허용가능한 확률분포 차이의 범위를 정의하여 T-근접성을 적용하는 메서드\"\"\"\n",
    "        T_data = dict()\n",
    "\n",
    "        if 0 <= tolerance <= 1: \n",
    "            # threshold\n",
    "            vector = np.array(self._dataframe[sensitive_attribute])\n",
    "            super().categorizeEquivalentClass(quasi_identifiers)\n",
    "\n",
    "            for group_key, index_value in self.equivalent_class.items():\n",
    "                # 1. Empirical Cummulative Probability Distribution\n",
    "                qi_distribution[group_key] = self.checkSensitivesDistribution(vector[index_value], sensitive_attribute)\n",
    "                total_distribution[group_key] = self.checkSensitivesDistribution(vector, sensitive_attribute)\n",
    "                    # self._dataframe.loc[index_value, sensitive_attribute]\n",
    "                    # .value_count(normalize = True) = .value_counts() / sum \n",
    "\n",
    "                # 2. Earth's Mover Distance\n",
    "                emd = self.earthMoversDistance(qi_distribution, total_distribution)\n",
    "\n",
    "                # 3.\n",
    "                if emd < tolerance:\n",
    "                    T_data[group_key] = index_value\n",
    "                else:\n",
    "                    print(group_key, len(unique_sensitive_values))\n",
    "            self.T_data = T_data\n",
    "        else: \n",
    "            ValueError(\"입력받은 {}은 허용가능한 동질집합과 전체집단 간 확률분포 차이의 범위로서 유효하지 않습니다.\".format(tolerance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc113f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t = T_Closeness(dataframe = DATA_FINANCE)\n",
    "# t.applyTCloseness(quasi_identifiers = [\"HOME_TYPE\", \"TF_LOAN\", \"TF_PENSION\"], tolerance = 0.1, sensitive_attribute = \"AMT_CREDITLOAN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f4f8b3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc146fa",
   "metadata": {},
   "source": [
    "5.1. **일반화 클래스**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86423a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pseudonymizer.pseudonymizer import Pseudonymizer\n",
    "from datetime import datetime\n",
    "\n",
    "class CategorizationOfCharacter(Pseudonymizer):\n",
    "    \"\"\"문자형으로 저장된 정보에 대하여 상위의 개념으로 범주화하는 가명처리기법 구체클래스\"\"\"    \n",
    "    def __init__(self, category_type: str):\n",
    "        self.category_type = category_type\n",
    "    \n",
    "    def pseudonymizeData(self, input_string: str, category_mapping: dict):\n",
    "        \"\"\"식별성이 높은 그룹을 하나로 묶는 메서드\n",
    "        일반적으로 나이 + 주소 + 성별 조합(동질 집합)이 재식별 가능성 있음\n",
    "        주소 | 시군구만 남기고 읍면동 단위 삭제\n",
    "        \n",
    "        입력값\n",
    "        ------\n",
    "        실행 클래스 Pseudonym 자체에서 열 벡터 자체가 아닌 **특정 열의 개별 레코드 형태**로 \n",
    "        입력받아 가명처리 기법을 적용하므로 별도로 자료형으로 제약 요건을 두지 아니함\n",
    "        입력값을 특정 범주로 분류하기 위한 전제 조건\n",
    "        : 실행 클래스에 범주 파악을 위한 Counter함수 적용하는 메서드 정의해야 함\n",
    "        \n",
    "        출력값\n",
    "        ------\n",
    "        조건에서 정의한 특정속성의 개별레코드별 그룹값 할당\n",
    "        \"\"\"\n",
    "        if self.category_type == \"date\":\n",
    "            return self.pseudonymizeDate(input_string)\n",
    "        elif self.category_type == \"user_definition\":\n",
    "            return self.pseudonymizeDefinition(input_string, category_mapping)\n",
    "        else:\n",
    "            raise ValueError(f\"{self.category_type}은 유효한 범주화 기법 적용 유형이 아닙니다.\")\n",
    "    \n",
    "    def pseudonymizeDate(self, date_time):\n",
    "        \"\"\"개인과 관련된 날짜 정보(자격 취득일자, 합격일 등)는 연 단위로 처리\"\"\"\n",
    "        if isinstance(date_time, datetime):\n",
    "            # datetime.datetime객체일 경우 날짜 문자열로 반환\n",
    "            # 2023-06-03\n",
    "            date_time = date_time.strftime(\"%Y-%m\")\n",
    "            return date_time\n",
    "        try:\n",
    "            # 날짜 문자열의 길이를 확인하여 연월일인지 연월인지 구분\n",
    "            if len(date_time) == 8:\n",
    "            # 20230603\n",
    "                date = datetime.strptime(date_time, \"%Y%m%d\")\n",
    "                return date.strftime(\"%Y-%m\")  \n",
    "                # 일시 삭제 후 연월로 변환\n",
    "            elif len(date_time) == 6:\n",
    "            # 202306\n",
    "                date = datetime.strptime(date_time, \"%Y%m\")\n",
    "                return date.strftime(\"%Y-%m\")  \n",
    "                # datetime 형식이 아닐 때, 연월로 변환\n",
    "            else:\n",
    "                raise ValueError(f\"{date_time}은 유효한 날짜 형식이 아닙니다.\")\n",
    "        except ValueError:\n",
    "            return f\"{date_time}은 유효한 날짜 형식이 아닙니다.\"  \n",
    "            # 에러 출력문 수정\n",
    "    \n",
    "    def pseudonymizeDefinition(self, string_tobeclassified, category_mapping: dict):\n",
    "        \"\"\"직접 특정 범주에 속하는 문자열 리스트를 딕셔너리 키, 값으로 입력\n",
    "        서울특별시 141,704개의 고유필지 → 2023년 기준 서울특별시 1,650개의 골목상권코드으로 그룹핑할 수 있도록 유형화\n",
    "        코스피 상장주식회사 종목 810개 → 24개 업종 분류로 범주화\"\"\"\n",
    "        for category, string_list in category_mapping.items():\n",
    "            # key는 범주이면서 value는 문자열 리스트일 때\n",
    "            if string_tobeclassified in string_list: \n",
    "                # 입력받은 문자열이 for루프에 걸린 문자열 리스트의 원소인 경우 해당 범주형 반환\n",
    "                # 접근 연산 시간복잡도를 줄이기 위한 시도는?\n",
    "                # 현재의 배열과 같이 링크드 리스트의 경우 원하는 노드에 접근하는 시간은 몇 번째 인덱스인지에 비례\n",
    "                return category\n",
    "        return \"other types\"\n",
    "            # 없으면 기타\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7340e5dc-54e9-469d-bdde-b0e3df000525",
   "metadata": {},
   "source": [
    "내장함수 map + set 자료형 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2516d461-f8ee-4697-a573-d3577b4cdd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_pseudonymizeDefinition(self, string_tobeclassified, category_mapping: dict):\n",
    "\n",
    "    def make_category(input_string, category_set):\n",
    "        if input_string in category_set:\n",
    "            return category\n",
    "        return \"other types\"\n",
    "\n",
    "    re_li = list(map(make_category, string_tobeclassified, category, string_set in category_mapping.items())\n",
    "    \n",
    "    # for category, string_set in category_mapping.items():\n",
    "    #     if string_tobeclassified in string_set:\n",
    "    #         return category\n",
    "    # return \"other types\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d8cb08-3cba-4a55-857c-e3ad12d22cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_date_object = CategorizationOfCharacter(category_type=\"user_definition\")\n",
    "# test_define_result = DATA_RETAIL[\"GENDER\"].apply(lambda data: test_date_object.pseudonymizeData(input_string=data, category_mapping={\"M\": set([\"male\"]), \"F\": set([\"female\"])}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258d831a-c8b7-4ffa-b099-18073bb069b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pseudonymizeDefinition3(self, string_tobeclassified, category_mapping: dict):\n",
    "    for category, string_list in category_mapping.items():\n",
    "        linked_list = deque(string_list)\n",
    "\n",
    "        if string_tobeclassified in linked_list:\n",
    "            return category\n",
    "\n",
    "    return \"other types\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b7fd15-6203-4b17-b033-a5aee5a81ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pseudonymizeDefinition4(self, string_tobeclassified, category_mapping: dict):\n",
    "    for category, string_list in category_mapping.items():\n",
    "        string_set = set(string_list)\n",
    "\n",
    "        if string_tobeclassified in string_set:\n",
    "            return category\n",
    "\n",
    "    return \"other types\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6106f966-77d6-46be-9977-cefa3512e9c9",
   "metadata": {},
   "source": [
    "pseudonymizeDefinition 메서드 numpy 단위 연산 튜토리얼 코드\n",
    "- 보통 numpy array 연산이 일반 for문보다 속도가 빠르기 때문에, pandas 데이터를 다루는 클래스 및 함수의 특성상 numpy 연산을 시도하기 적합하다고 판단함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9464eb45-182b-4535-9b77-808119281dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pseudonymizeDefinition2(series_tobeclassified, category_mapping: dict):\n",
    "    \"\"\"\n",
    "    pseudonymizeDefinition 함수를, pandas column 단위로 파라미터를 넣어 numpy로 연산하는 함수\n",
    "    보통 numpy 연산이 일반 for문보다 속도가 빠르기 때문에, pandas 데이터를 다루는 특성상 numpy 연산을 시도함\n",
    "    \"\"\"\n",
    "    result = np.full_like(series_tobeclassified, \"other types\")\n",
    "    for category, string_list in category_mapping.items():\n",
    "        result = np.where(np.isin(series_tobeclassified, string_list), category, result)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d92418-95c3-4732-94c3-d549469e3d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tr = pseudonymizeDefinition2(DATA_RETAIL[\"GENDER\"], {\"M\": [\"male\"], \"F\": [\"female\"]})\n",
    "# tr, len(tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ae4eec-c693-450a-8119-ac38c2a557e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# di = {\"M\": [\"male\", \"Man\"], \"F\": [\"female\", \"Woman\"]}\n",
    "# data = np.array([\"male\", \"male\", \"female\", \"female\", \"male\"])\n",
    "# for category, string_list in di.items():\n",
    "    # res = np.where(np.isin(data, string_list), category, \"nn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2435c80-fe28-421c-b3be-0e3e9c41291d",
   "metadata": {},
   "source": [
    "기존 일반화 메서드 pseudonymizeDefinition 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62bda98a-36b1-416a-b432-fbb5883797b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test_date_object = CategorizationOfCharacter(category_type=\"user_definition\")\n",
    "# test_define_result = DATA_RETAIL[\"GENDER\"].apply(lambda data: test_date_object.pseudonymizeData(input_string=data, category_mapping={\"M\": [\"male\"], \"F\": [\"female\"]}))\n",
    "# test_define_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ec18a0",
   "metadata": {},
   "source": [
    "날짜 정보 범주화 객체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9574a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_date_object = CategorizationOfCharacter(category_type = \"date\")\n",
    "# test_date_category = DATA_RETAIL[\"JOIN_DATE\"].apply(lambda data: test_date_object.pseudonymizeData(input_string = data, category_mapping = None))\n",
    "# display(test_date_category.head(5))\n",
    "# display(test_date_category[test_date_category.str.contains(\"유효한 날짜 형식이 아닙니다.\")].head(5))\n",
    "# test_date_category"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46417572",
   "metadata": {},
   "source": [
    "사용자 정의 특정 그룹에 해당하는 문자열 리스트를 딕셔너리 키, 값으로 범주화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdb6613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_date_object = CategorizationOfCharacter(category_type=\"user_definition\")\n",
    "# test_define_result = DATA_RETAIL[\"GENDER\"].apply(lambda data: test_date_object.pseudonymizeData(input_string=data, category_mapping={\"M\": [\"male\"], \"F\": [\"female\"]}))\n",
    "# DATA_RETAIL[\"GENDER\"].head(5)\n",
    "# Counter(test_define_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e81910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pseudonymizer.pseudonymizer import Pseudonymizer\n",
    "# from datetime import datetime\n",
    "\n",
    "class CategorizationOfNumeric(Pseudonymizer):\n",
    "    \"\"\"수치(연속형) 데이터를 임의의 수를 기준으로 범위(범주형)으로 설정하는 가명처리기법 구체클래스 \"\"\"\n",
    "    def __init__(self, numeric_type):\n",
    "        self.numeric_type = numeric_type\n",
    "    \n",
    "    def pseudonymizeData(self, input_numeric: float, grouping_standard):\n",
    "        \"\"\"식별성이 높은 그룹을 하나로 묶는 메서드\"\"\"\n",
    "        if self.numeric_type == \"age\":\n",
    "            return self.pseudonymizeAge(input_numeric, grouping_standard)\n",
    "        elif self.numeric_type == \"income\":\n",
    "            return self.pseudonymizeIncome(input_numeric, grouping_standard)\n",
    "        elif self.numeric_type == \"user_definition\":\n",
    "            return self.pseudonymizeDefinition(input_numeric, grouping_standard)\n",
    "        else: \n",
    "            raise ValueError(f\"{self.numeric_type}은 유효한 범주화 기법 적용 유형이 아닙니다.\")\n",
    "    \n",
    "    def pseudonymizeAge(self, birthday, grouping_standard):\n",
    "        \"\"\"연령 범주화 메서드\n",
    "        일반적으로 나이 + 주소 + 성별 조합(동질 집합)이 재식별 가능성 있으므로\n",
    "        5세, 10세 단위 또는 초중후반으로 만 나이 범주화\"\"\"\n",
    "        currentdate = datetime.now().date()\n",
    "        if (currentdate.month, currentdate.day) < (birthday.month, birthday.day):\n",
    "        # 아직 현재 날짜가 생일 전인 경우 만 나이 계산 시 한 살 제외\n",
    "            age = currentdate.year - birthday.year - 1\n",
    "        else:\n",
    "            age = currentdate.year - birthday.year\n",
    "        \n",
    "        if grouping_standard in [\"3bin\", \"5bin\", \"10bin\"]:\n",
    "            if grouping_standard == \"3bin\":\n",
    "            # 0,1,2(초반) / 3,4,5,6(중반) / 7,8,9(후반)\n",
    "                sort = (age % 10) // 3\n",
    "                range = (age // 10) * 10\n",
    "                if sort == 0:\n",
    "                    return f\"{range}대 초반\"\n",
    "                elif sort == 1:\n",
    "                    return f\"{range}대 중반\"\n",
    "                elif sort == 2:\n",
    "                    return f\"{range}대 후반\"\n",
    "                else: \n",
    "                    return\n",
    "            elif grouping_standard == \"5bin\":\n",
    "            # 0,1,2,3,4(초반) / 5,6,7,8,9(후반)\n",
    "                return f\"{(age // 10) * 10}대 초반\" if (age % 10) < 5 else f\"{(age // 10) * 10}대 후반\"\n",
    "            elif grouping_standard == \"10bin\":\n",
    "            # 10대~100대\n",
    "                return f\"{(age // 10) * 10}대\"\n",
    "            else:\n",
    "                raise ValueError(\"입력받은 {}은 연령 범주화 기준으로 유효하지 않습니다.\".format(grouping_standard))\n",
    "        \n",
    "    def pseudonymizeIncome(self, income, grouping_standard):\n",
    "        \"\"\"소득금액 범주화 메서드\n",
    "        소득을 전체 대상자를 9분위(2024년 건강보험료 1인 기준 소득분위)로 균등 분할\"\"\"\n",
    "        if grouping_standard is None:\n",
    "            threshold_list= [1841500, 2025500, 2675000, 2897000, 3120000, 3343000, 3566000, 3789000, 4012000]\n",
    "            for index, threshold in enumerate(threshold_list, start = 1):\n",
    "                if income <= threshold:\n",
    "                    return f\"{index}분위\"\n",
    "        else:\n",
    "        # While grouping_standard True:\n",
    "            grouping_standard.sort()\n",
    "            # 오름차순 정렬 시 일반적으로 사용하는 버블 정렬은 O(N**2)이므로 \n",
    "            # 시간복잡도 낮추려면 병합 정렬 O(NlogN) 활용 -> 추후 merge_sort() 메서드 적용하여 리팩토링\n",
    "            for index, grouping_standard in enumerate(grouping_standard, start = 1):\n",
    "                if income <= grouping_standard:\n",
    "                    return f\"{index}분위\"\n",
    "        \n",
    "    def pseudonymizeDefinition(self, numeric_tobeclassified, category_mapping: dict):\n",
    "        \"\"\"사용자가 직접 구간을 설정하도록 하는 범주화 메서드\n",
    "        intervals: [(0, 1000), (1000, 5000), (5000, 10000)]\n",
    "        \"\"\"\n",
    "        for category, interval in category_mapping.items():\n",
    "            if not isinstance(interval, tuple) or len(interval) != 2:\n",
    "                return f\"유효하지 않은 구간 {interval}입니다.\"\n",
    "            \n",
    "            lower, upper = interval # tuple(lower, upper)\n",
    "            if lower <= numeric_tobeclassified <= upper:\n",
    "                return category\n",
    "            return \"other types\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930f682b-1171-4e19-92d9-d8135dee52cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_date_object = CategorizationOfCharacter(category_type=\"user_definition\")\n",
    "# test_define_result = DATA_RETAIL[\"GENDER\"].apply(lambda data: test_date_object.pseudonymizeData(input_string=data, category_mapping={\"M\": [\"male\"], \"F\": [\"female\"]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05026cb-c9fe-4def-84fe-f5daf58c5218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numeric_category = CategorizationOfNumeric(numeric_type=\"age\")\n",
    "# test_numeric_result = DATA_RETAIL[\"AGE\"].apply(lambda data: numeric_category.pseudonymizeData(input_numeric=data, grouping_standard=\"5bin\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed9e7a3-5257-4363-a608-c21d867aadc3",
   "metadata": {},
   "source": [
    "수치형 데이터 범위 설정 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f61acb0-bc0c-42d1-a75e-45d7de8fd147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pseudonymizer.pseudonymizer import Pseudonymizer\n",
    "# from datetime import datetime\n",
    "\n",
    "class CategorizationOfColumn(Pseudonymizer):\n",
    "    \"\"\"수치(연속형) 데이터를 임의의 수를 기준으로 범위(범주형)으로 설정하는 가명처리기법 구체클래스 \"\"\"\n",
    "    def __init__(self, numeric_type, grouping_standard, right, ascending):\n",
    "        self.numeric_type = numeric_type\n",
    "        self.grouping_standard = grouping_standard\n",
    "        self.right = right\n",
    "        self.ascending = ascending\n",
    "    \n",
    "    def pseudonymizeData(self, df):\n",
    "        \"\"\"식별성이 높은 그룹을 하나로 묶는 메서드\"\"\"\n",
    "        if self.numeric_type == \"bin\":\n",
    "            return self.pseudonymizeAmountbyBin(df, self.grouping_standard, self.right, self.ascending)\n",
    "        elif self.numeric_type == \"pct\":\n",
    "            return self.pseudonymizeAmountbyPct(df, self.grouping_standard, self.right, self.ascending)        \n",
    "        else: \n",
    "            raise ValueError(f\"{self.numeric_type}은 유효한 범주화 기법 적용 유형이 아닙니다.\")\n",
    "\n",
    "    def makeLabels(self, num_type, df, grouping_standard, ascending: bool):\n",
    "        \"\"\"범주화 중 필요한 label을 만들어주는 클래스\"\"\"\n",
    "        if num_type == \"pct\":\n",
    "\n",
    "            labels = []\n",
    "            \n",
    "            for i in range(len(grouping_standard)):\n",
    "                if i == 0:\n",
    "                    label = f\"{grouping_standard[i]} 미만\"\n",
    "                    labels.append(label)\n",
    "                elif 0 < i < len(grouping_standard) - 1:\n",
    "                    label = f\"{grouping_standard[i-1]} ~ {grouping_standard[i]}\"\n",
    "                    labels.append(label)\n",
    "                else:\n",
    "                    label1 = f\"{grouping_standard[i-1]} ~ {grouping_standard[i]}\"\n",
    "                    labels.append(label1)\n",
    "                    label2 = f\"{grouping_standard[i]} 이상\"\n",
    "                    labels.append(label2)\n",
    "\n",
    "            if ascending == False:\n",
    "                return labels.reverse()\n",
    "            elif ascending == True:\n",
    "                return labels\n",
    "            else:\n",
    "                raise ValueError(\"ascending 파라미터는 True / False 형태로 입력해 주십시오.\")\n",
    "\n",
    "\n",
    "        elif num_type == \"bin\":\n",
    "\n",
    "            labels = []\n",
    "            \n",
    "            category_values = pd.cut(df, bins = grouping_standard).value_counts(sort=False)\n",
    "\n",
    "            for category in list(category_values.index):\n",
    "                start_value = category.left\n",
    "                end_value = category.right\n",
    "                labels.append(f\"{start_value} ~ {end_value}\")\n",
    "\n",
    "            if ascending == False:\n",
    "                return labels.reverse()\n",
    "            elif ascending == True:\n",
    "                return labels\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"{num_type}은 유효한 범주화 기법 적용 유형이 아닙니다.\")\n",
    "\n",
    "    \n",
    "    def pseudonymizeAmountbyBin(self, df, grouping_standard, right: bool, ascending: bool):\n",
    "        \"\"\"기타 금액 구간별 범주화 메서드\n",
    "        신용공여금액(예: 한도/건별대출, 담보대출, 리스/카드할부금융서비스 등)의 일정 급간화\n",
    "        다만, pd.cut과의 차별점 없으며, pandas 내장 함수를 활용하여 범주화하는 것이 훨씬 효율적\n",
    "\n",
    "        - 등급명 전부 입력 받고 그 등급명대로 매칭해주는 케이스 (O)\n",
    "        - 등급명 없이 갯수만 입력받고, 등급명은 “10~30”, “30~50” 이런 식으로 매칭해주는 케이스 (O)\n",
    "        - \"이상 ~ 미만\" 과 \"초과 ~ 이하\" 중 선택지 부여하는 케이스 (각각 right = False, right = True) (O)\n",
    "        - 등급을 오름차순(작은것 ~ 큰것) / 내림차순(큰것 ~ 작은것) 중 어느 순으로 매길지 고르는 케이스 (레이블 순서를 뒤집으면 내림차순이 됨)\n",
    "            -> ascending = True 면 오름차순, 아니면 내림차순 (O)\n",
    "        - 해당 선택지 및 케이스들을 메서드 1개로 올릴지, 메서드 여러개로 분리할지 결정 필요\n",
    "        \"\"\"\n",
    "        if isinstance(grouping_standard, list):\n",
    "            num = len(grouping_standard)\n",
    "            df = pd.cut(df, bins = num, labels = grouping_standard, right = right)\n",
    "            return df\n",
    "\n",
    "        elif isinstance(grouping_standard, int):\n",
    "            labels = self.makeLabels(\"bin\", df, grouping_standard, ascending = ascending)                              \n",
    "            df = pd.cut(df, bins = grouping_standard, labels = labels, right = right)\n",
    "            return df\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"grouping_standard는 list 또는 int 타입으로 입력해 주십시오.\")\n",
    "                \n",
    "        \n",
    "    def pseudonymizeAmountbyPct(self, df, grouping_standard, right: bool, ascending: bool):\n",
    "        \"\"\"기타 금액 백분위에 의한 범주화 메서드\n",
    "        개인사업자의 추청매출액/평당월임대료를 백분위수에 따라 매출등급화(90~100%, 65~90%, 35~65%, 10~35%, 0~10%)\n",
    "\n",
    "        - 각 레코드별 등수 구하기 (중복값은 가장 낮은 순위로)\n",
    "        - 백분위수 = ((등수 - 1) / 컬럼 레코드 갯수) * 100\n",
    "        - 백분위수별로 pd.cut\n",
    "        \"\"\"\n",
    "        rank_df = df\n",
    "        rank_df[\"rank\"] = df.rank(method='min')\n",
    "        \n",
    "        percentiles = []\n",
    "\n",
    "        for rank in rank_df[\"rank\"]:\n",
    "            percentile = ((rank - 1) / len(df['rank'])) * 100\n",
    "            percentiles.append(percentile)\n",
    "\n",
    "        rank_df[\"percentile\"] = percentiles\n",
    "        new_labels = self.makeLabels(\"pct\", df, grouping_standard, ascending)\n",
    "        bins = [0] + grouping_standard + [100]\n",
    "        result_df = pd.cut(rank_df[\"percentile\"], bins = bins, labels = new_labels, right = right)\n",
    "        return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a52d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tt = CategorizationOfColumn(numeric_type=\"bin\", grouping_standard = [\"A\", \"B\", \"C\", \"D\", \"E\"], right = False, ascending = True)\n",
    "# tt3 = CategorizationOfColumn(numeric_type=\"bin\", grouping_standard = 5, right = False, ascending = False)\n",
    "# tt3 = tt.pseudonymizeData(df = DATA_FINANCE[\"AMT_CREDITCARD_PAYMENT\"])\n",
    "\n",
    "# Test Scipt for pseudonymizeAmountbyBin method\n",
    "# pseudonym_data = Pseudonym(dataframe = DATA_FINANCE)\n",
    "# pseudonym_data.addDictionary(column = \"AMT_CREDITCARD_PAYMENT\", pseudonymizers = [tt])\n",
    "# pseudonym_data.addDictionary(column = \"AMT_CREDITCARD_PAYMENT\", pseudonymizers = [tt3])\n",
    "# pseudonym_data.pseudonymizeData()\n",
    "# pseudonym_data.getPseudonymizedDataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385a602d-9b15-46e7-9dde-8cf7b6faa2d3",
   "metadata": {},
   "source": [
    "pseudonymizeAmountbyPct 메서드 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ba4854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Scipt for pseudonymizeAmountbyPct method\n",
    "# tt2 = CategorizationOfColumn(numeric_type=\"pct\", grouping_standard = [20, 50, 70, 80], right = True, ascending = False)\n",
    "# pseudonym_data = Pseudonym(dataframe = DATA_FINANCE)\n",
    "# pseudonym_data.addDictionary(column = \"AMT_CASHADVANCE_PAYMENT\", pseudonymizers = [tt2])\n",
    "# pseudonym_data.pseudonymizeData()\n",
    "# pseudonym_data.getPseudonymizedDataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ee5fc0-823c-41a1-9ed2-75fdfa54e57b",
   "metadata": {},
   "source": [
    "부분총계 클래스\n",
    "\n",
    "* 총계처리:(총합집계, 범주/범위화기법과혼용)\n",
    "    - 추정매출액=원시매출액*추정현금비율*카드사시장점유비(MS)\n",
    "    - 지역별업종추정평균매출액=Σ(업소별추정매출액)/업소수\n",
    "    - 매출범위로환산:5,314,000원→추정매출5,000천원∼6,000천원\n",
    "\n",
    "* 총계: (합계, 평균, 빈도, 추세, 추정)\n",
    "    - 소득: 개인의소득→ 소지역단위로총계화\n",
    "    - 예) <삼봉아파트101동구역> \n",
    "    - 홍길동연수입34,100,000원 / 성춘향연수입27,000,000원 / 심학도연수입41,000,000원\n",
    "    - → 삼봉아파트101동연수입(총계, 평균, 등록고객수, 작년대비성장, 대푯값)\n",
    "    - 적용예시) 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0434d81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pseudonymizer.pseudonymizer import Pseudonymizer\n",
    "\n",
    "class MicroAggregation(Pseudonymizer):\n",
    "    \"\"\"특정 그룹의 속성에서 정확한 통계값을 확인하는 가명처리기법 구체 클래스\n",
    "       클래스를 통해 도출할 부분 통계값: 평균, 총합, 빈도, 추세, 추정값\n",
    "    \"\"\"\n",
    "    def __init__(self, cal_type, category):\n",
    "        self.cal_type = cal_type\n",
    "        self.category = category\n",
    "\n",
    "    # def selectMicroData(self, df, category, equivalent_class):\n",
    "    #     # print(equivalent_class)\n",
    "    #     # print(category)\n",
    "    #     return equivalent_class[category]\n",
    "        \n",
    "\n",
    "    def pseudonymizeData(self, df, column, equivalent_class):\n",
    "        \"\"\"Pseudonym 클래스로 실행하는 메서드\"\"\"\n",
    "        # condition = self.selectMicroData(df, self.category, equivalent_class)\n",
    "        \n",
    "        if self.cal_type == \"avr\":\n",
    "            return self.microAverage(df, column, self.category, equivalent_class)\n",
    "        elif self.cal_type == \"sum\":\n",
    "            return self.microSum(df, column, self.category, equivalent_class)\n",
    "        elif self.cal_type == \"mdn\":\n",
    "            return self.microMedian(df, column, self.category, equivalent_class)\n",
    "        elif self.cal_type == \"max\":\n",
    "            return self.microMax(df, column, self.category, equivalent_class)\n",
    "        elif self.cal_type == \"min\":\n",
    "            return self.microMin(df, column, self.category, equivalent_class)\n",
    "        elif self.cal_type == \"fqr\":\n",
    "            return self.microFrequency(df, column, self.category, equivalent_class)\n",
    "        elif self.cal_type == \"trd\":\n",
    "            return self.microTrend(df, column, self.category, equivalent_class)\n",
    "        elif self.cal_type == \"ded\":\n",
    "            return self.microDeduction(df, column, self.category, equivalent_class)\n",
    "        else:\n",
    "            raise ValueError(f\"{self.cal_type}은 유효한 부분총계 기법 적용 유형이 아닙니다.\")\n",
    "\n",
    "    def microAverage(self, df, column, category, equivalent_class):\n",
    "        \"\"\"그룹별 평균 구하는 메서드\"\"\"\n",
    "        condition = equivalent_class[category]   # category가 equivalent_class 에 없는 경우에 ValueError 띄워주기\n",
    "        selectedData = df.iloc[condition]\n",
    "        \n",
    "        partialAverage = selectedData[column].mean()\n",
    "        df.loc[condition, column] = partialAverage\n",
    "        return df[column]\n",
    "        \n",
    "\n",
    "    def microSum(self, df, column, category, equivalent_class):\n",
    "        \"\"\"그룹별 총합 구하는 메서드\"\"\"\n",
    "        condition = equivalent_class[category]\n",
    "        selectedData = df.iloc[condition]\n",
    "        \n",
    "        partialSum = selectedData[column].sum()\n",
    "        df.loc[condition, column] = partialSum\n",
    "        return df[column]\n",
    "\n",
    "    def microMedian(self, df, column, category, equivalent_class):\n",
    "        \"\"\"그룹별 중간값 구하는 메서드\"\"\"\n",
    "        condition = equivalent_class[category]\n",
    "        selectedData = df.iloc[condition]\n",
    "        \n",
    "        partialAverage = selectedData[column].median()\n",
    "        df.loc[condition, column] = partialAverage\n",
    "        return df[column]\n",
    "\n",
    "    def microMax(self, df, column, category, equivalent_class):\n",
    "        \"\"\"그룹별 최댓값 구하는 메서드\"\"\"\n",
    "        condition = equivalent_class[category]\n",
    "        selectedData = df.iloc[condition]\n",
    "        \n",
    "        partialMax = selectedData[column].max()\n",
    "        df.loc[condition, column] = partialMax\n",
    "        return df[column]\n",
    "\n",
    "    def microMin(self, df, column, category, equivalent_class):\n",
    "        \"\"\"그룹별 최솟값 구하는 메서드\"\"\"\n",
    "        condition = equivalent_class[category]\n",
    "        selectedData = df.iloc[condition]\n",
    "        \n",
    "        partialMin = selectedData[column].min()\n",
    "        df.loc[condition, column] = partialMin\n",
    "        return df[column]\n",
    "\n",
    "    def microFrequency(self, df, column, category, equivalent_class):\n",
    "        \"\"\"그룹별 최빈값 구하는 메서드\"\"\"\n",
    "        condition = equivalent_class[category]\n",
    "        selectedData = df.iloc[condition]\n",
    "        \n",
    "        partialFrequency = selectedData[column].mode()\n",
    "        df.loc[condition, column] = partialFrequency\n",
    "        return df[column]\n",
    "\n",
    "    def microTrend(self, df, column, category, equivalent_class):\n",
    "        \"\"\"그룹별 추세 구하는 메서드\"\"\"\n",
    "        pass\n",
    "\n",
    "    def microDeduction(self, df, column, category, equivalent_class):\n",
    "        \"\"\"그룹별 추정값 구하는 메서드\n",
    "           원본 레코드에 특정 비율이나 수를 곱하여 추정값을 구하는 메서드\n",
    "           \n",
    "           **참고\n",
    "           - 추정매출액 = 원시매출액 * 추정현금비율 * 카드사시장점유비(MS)\n",
    "            지역별업종추정평균매출액 = ∑(업소별추정매출액) / 업소수\n",
    "            매출범위로 환산 : 5,314,000원 → 추정매출 5,000천원∼6,000천원 (3. 범주 / 범위화 기법과 혼용)\n",
    "\n",
    "            외부 변수를 집어넣어서 연산하는 경우, 혹은 내부 컬럼끼리 연산하는 경우\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3e2a45-4344-451a-9b8a-c147e4a53ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA_FINANCE.iloc[\n",
    "    # PseudonymizeFinanceData.equivalent_class[('비거주용 건물(상가', 'Y', 'Y')], :][\n",
    "    # (DATA_FINANCE[\"AMT_CREDITLOAN\"] >= 0) & (DATA_FINANCE[\"AMT_CASHADVANCE_PAYMENT\"] > 8000000)] \n",
    "\n",
    "# DATA_FINANCE.iloc[\n",
    "    # PseudonymizeFinanceData.equivalent_class[('영업 겸용 단독주택', 'Y', 'Y') ], :][\n",
    "    # (DATA_FINANCE[\"AMT_CREDITLOAN\"] >= 0) & (DATA_FINANCE[\"AMT_CASHADVANCE_PAYMENT\"] > 8000000)] \n",
    "\n",
    "# 94,999명 중 대출실행고객은 9466명\n",
    "# ('영업 겸용 단독주택', 'Y', 'Y') ('비거주용 건물(상가', 'Y', 'Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50ceaef",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06016c7",
   "metadata": {},
   "source": [
    "5.2. **일반화 클래스 - 이상치 탐색 및 처리**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1dc5436",
   "metadata": {},
   "source": [
    "로컬 일반화\n",
    "- minimality attack\n",
    "- 모든 레코드에 대해 일반화 하는 것이 아니고 특정 집단만 일반화하는 기술"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae47818a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pseudonymizer.pseudonymizer import Pseudonymizer\n",
    "\n",
    "class LocalGeneralization(Pseudonymizer):\n",
    "    \"\"\"분포상의 특이성으로 인해 식별 가능성이 높아지는 경우 해당 부분만 일반화를 적용하는 가명처리기법 구체클래스\"\"\"\n",
    "    def pseudonymizeData(self, index_list: List[int]):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4dbd72e",
   "metadata": {},
   "source": [
    "상하단 코딩\n",
    "\n",
    "- 양끝단의 특이값이 식별성이 높으므로 이를 그룹화\n",
    "- 결국 하위의 공통된 특성을 찾아 상위 개념으로 묶는 기법\n",
    "(특정 정보를 해당 그룹의 대푯값이나 구간값으로 변환)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee2843bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TopandBottomCoding(Pseudonymizer):\n",
    "    \"\"\"적은 수의 분포를 가진 양 끝단의 정보를 범주화 등의 기법을 적용하여 식별성을 낮추는 가명처리기법 구체클래스\"\"\"\n",
    "    def pseudonymizeData(self, value):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d503963f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ./pseudonymizer/pseudonymizer/deidentificationTechnique/equivalent_class.py\n",
    "\n",
    "class EquivalentClass:\n",
    "    \"\"\"개인식별가능정보 속성을 기준으로 데이터를 그룹화하는 부모 클래스\n",
    "    \n",
    "    준식별자를 이용한 그룹화 기법 의사코드\n",
    "    --------------------------------------\n",
    "    data grouping using quasi-identifier\n",
    "    Input : PI(Personal Information)\n",
    "    Output : Grouped PI\n",
    "\n",
    "    grouped_PI = dict()\n",
    "    for identifier, quasi in PI.items():\n",
    "        key = quasi[0] + quasi[1] + quasi[2] + quasi[3]\n",
    "        if key in grouping_PI:\n",
    "            grouping_PI[key].append(identifier)\n",
    "        else:\n",
    "            grouping_PI[key] = []\n",
    "            grouping_PI[key].append[identifier]\n",
    "\n",
    "        return grouping_PI\n",
    "    \"\"\"\n",
    "    def __init__(self, dataframe):\n",
    "        self._dataframe = dataframe\n",
    "        self.equivalent_class = {}\n",
    "\n",
    "    def __str__(self):\n",
    "        # __repr__\n",
    "        \"\"\"캡슐화된 데이터셋의 속성(컬럼)정보를 반환하는 메서드\"\"\"\n",
    "        return self._dataframe.info()\n",
    "    \n",
    "    def categorizeEquivalentClass(self, attributes: List[str]):\n",
    "        \"\"\"각 행(레코드)에 대한 개인식별가능정보 속성(컬럼)들 사이에 동질 집합을 확인하는 메서드\"\"\"\n",
    "        groupby_data = self._dataframe.groupby(attributes)\n",
    "        \n",
    "        for group, data in groupby_data:\n",
    "            if len(group) > 1:\n",
    "                key = tuple(group)\n",
    "                # 딕셔너리에서 키 값으로 리스트(동적 타입)는 사용할 수 없으므로 튜플로 변환\n",
    "                self.equivalent_class[key] = data.index.tolist()\n",
    "                # 동질 집합에 해당하는 행(레코드)의 인덱스 번호를 키 값으로 조회되도록 저장\n",
    "\n",
    "    def removeDuplicatesInEquivalentClass(self):\n",
    "        \"\"\"각 동질집합 내 레코드 간 중복된 행을 제거하는 메서드\"\"\"\n",
    "        for group_key, index_value in self.equivalent_class.items():\n",
    "            unique_record = self._dataframe.loc[index_value, :].drop_duplicates()\n",
    "            # set(self._dataframe.loc[index_value, :])\n",
    "            self.equivalent_class[group_key] = unique_records.index.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e524c4",
   "metadata": {},
   "source": [
    "차분 프라이버시\n",
    "\n",
    "* 제약조건 : 데이터 공개 메커니즘만으로는 임의의 레코드가 포함된 데이터셋과 그렇지 않은 데이터셋을 구별하기 어려워야 한다.\n",
    "\n",
    "* 통계적 확률응답모형을 응용하여 원본 데이터에 노이즈를 추가하는 방법\n",
    "\n",
    "    (1) 라플라스 메커니즘\n",
    "        \n",
    "    * 라플라스 분포(laplace distribution)로부터 파생된 랜덤 노이즈 값\n",
    "    \n",
    "    * 분산이 개인정보의 민감도(sensitivity)/ε 상수와 비례하도록 설정된 라플라스 분포로부터 생성한 임의의 잡음\n",
    "    \n",
    "    * $f(x) = \\frac{1}{2b}exp[\\frac{-|x-\\mu|}{b}]$\n",
    "        \n",
    "    (2) 가우스 메커니즘\n",
    "\n",
    "    * ε 값과 관계된 평균과 분산을 가지는 가우스 분포로부터 생성한 임의의 잡음을 더하여(noise addition) 변조된 결과를 데이터 이용자에게 제공\n",
    "    \n",
    "    * $f(x) = \\frac1{\\sqrt{2\\pi\\sigma^2}}{exp}^\\frac{x-\\mu}{\\sigma}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e88b602d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ./pseudonymizer/pseudonymizer/deidentificationTechnique/differentialPrivacy.py\n",
    "\n",
    "# from pseudonymizer.pseudonymizer.deidentificationTechnique.equivalentClass import EquivalentClass\n",
    "# from typing import *\n",
    "\n",
    "class DifferentialPrivacy(EquivalentClass):\n",
    "    \"\"\"차분 프라이버시 클래스\n",
    "    Pseudonymizer와는 무관하게 수행되어도 되는지 고민해봐야 함\"\"\"\n",
    "    \n",
    "    def __init__(self, dataframe):\n",
    "        super().__init__(dataframe)\n",
    "        self.ratio_bounded = None \n",
    "        # ratio_bounded = epsilon(개인정보(가명정보) 보호 수준 결정)\n",
    "        self.sensitive_attribute = None\n",
    "        self.sensitivity = None\n",
    "    \n",
    "    def dataGlobalSensitivity(self):\n",
    "        \"\"\"\n",
    "        특정 레코드(식별가능한 개인) 유무에 따른 민감도 산출하는 메서드\n",
    "        * 전역 민감도란 (DB 테이블 쿼리 결과) - (이웃 DB의 동일한 쿼리 결과)의 차이\n",
    "        * 민감도 산출 시 gaussianPDF(), laplacePDF() 활용가능\n",
    "        * 테이블 전체가 아닌 동질집합 단위로 범위 수정하여 적용\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def gaussianMechanism(self, ratio_bounded: float):\n",
    "        \"\"\"가우스 메커니즘을 적용하여 특정 데이터 행에 랜덤 노이즈값을 추가하는 메서드\"\"\"\n",
    "        sigma = self.sensitivity / ratio_bounded\n",
    "        noise = np.random.normal(0, sigma, len(data))\n",
    "        return data + noise\n",
    "\n",
    "    def laplaceMechanism(self, ratio_bounded: float):\n",
    "        \"\"\"라플라스 메커니즘을 적용하여 특정 데이터 행에 랜덤 노이즈값을 추가하는 메서드\"\"\"\n",
    "        beta = self.sensitivity / ratio_bounded\n",
    "        noise = np.random.laplace(0, beta, len(data))\n",
    "        return data + noise\n",
    "    \n",
    "    def gaussianPDF(self, x, mu, sigma):\n",
    "        \"\"\"정규분포(가우시안) 확률밀도함수\"\"\"\n",
    "        return (1 / sqrt(2*pi*sigma**2)) * exp(-0.5*((x-mu) / sigma)**2)\n",
    "    \n",
    "    def laplacePDF(self, x, mu, scale_param):\n",
    "        \"\"\"라플라스분포 확률밀도함수\"\"\"\n",
    "        return (1 / (2*scale_param)) * exp(-abs(x-mu) / scale_param)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "05367d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pseudonymizer.pseudonymizer.deidentificationTechnique.equivalent_class import EquivalentClass\n",
    "# from pseudonymizer.pseudonymizer.deidentificationTechnique.kAnonimity import K_Anonymity\n",
    "# from pseudonymizer.pseudonymizer.deidentificationTechnique.lDiversity import L_Diversity\n",
    "# from pseudonymizer.pseudonymizer.deidentificationTechnique.tCloseness import T_Closeness\n",
    "\n",
    "# from typing import *\n",
    "\n",
    "class PrivacyPreservingModel:\n",
    "    \"\"\"개인식별가능정보 속성을 기준으로 그룹화된 데이터로 프라이버시 보호 모델을 적용하여 정량적인 위험성을 규정하는 실행 클래스\"\"\"\n",
    "    def __init__(self, dataframe):\n",
    "        self._dataframe = dataframe\n",
    "        self.equivalnt_class = EquivalentClass(self._dataframe)\n",
    "        self.Kanonymity = K_Anonymity(self._dataframe)\n",
    "        self.Ldiversity = L_Diversity(self._dataframe)\n",
    "        self.Tcloseness = T_Closeness(self._dataframe)\n",
    "        self.DPrivacy = DifferentialPrivacy(self._dataframe)\n",
    "        \n",
    "    def applyKAnonymityOrLDiversity(self, method: str, **kwargs):\n",
    "        \"\"\"K-익명성과 L-다양성 기법을 선택적으로 적용하는 메서드\n",
    "        input\n",
    "        -----\n",
    "        method: 프라이버시 보호 모델 메서드를 받고, \n",
    "        keyword arguments에 딕셔너리 형식으로 각 기법에 필요한 파라미터를 받아옴\"\"\"\n",
    "        if method == \"K\":\n",
    "            self.Kanonymity.applyKAnonymity(**kwargs)\n",
    "            return self.Kanonymity.K_data\n",
    "        elif method == \"L\":\n",
    "            self.Ldiversity.applyLDiversity(**kwargs)\n",
    "            return self.Ldiversity.L_data\n",
    "        elif method == \"LL\":            \n",
    "            self.Ldiversity.applyLocalLDiversity(**kwargs)\n",
    "            return self.Ldiversity.LocalL_data\n",
    "\n",
    "    def applyTCloseness(self, aquasi_identifiers: List[str], sensitive_attribute: str, tolerance: float):\n",
    "        \"\"\"T-근접성 기법을 적용하는 메서드\"\"\"\n",
    "        self.Tcloseness.applyTCloseness(quasi_identifiers, tolerance, sensitive_attribute)\n",
    "        return self.Tcloseness.T_data\n",
    "\n",
    "    def applyDPrivacy(self):\n",
    "        \"\"\"NEW : 차분 프라이버시 기법을 적용하는 메서드\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def __str__(self):\n",
    "        \"\"\"동질집합에 대한 정보를 문자열로 반환하는 메서드\"\"\"\n",
    "        return str(self.equivalent_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70904b9b-492f-4d78-85e8-e8d3fa7ff8ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9317fa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ded4bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a43135c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc832cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e49f2e13",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778beb80",
   "metadata": {},
   "source": [
    "6. **가명처리 실행 클래스**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fd392b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ./pseudonymizer/pseudonymizer.py\n",
    "\n",
    "# from abc import ABC, ABCMeta, abstractmethod\n",
    "# import pandas as pd\n",
    "    \n",
    "class Pseudonym:\n",
    "    def __init__(self, dataframe):\n",
    "        \"\"\"원본정보(재현데이터)와 가명처리 구체 클래스를 인스턴스 변수로 선언하는(초기화) 생성자\"\"\"\n",
    "        self._dataframe = dataframe\n",
    "        self.equivalent_class = {}\n",
    "        self._pseudonymizers = []\n",
    "        self._pseudonymDictionary = {}\n",
    "        \n",
    "    def __str__(self):\n",
    "        # __repr__\n",
    "        \"\"\"캡슐화된 데이터셋의 속성(컬럼)정보를 반환하는 메서드\"\"\"\n",
    "        return self._dataframe.info()\n",
    "    \n",
    "    def categorizeEquivalentClass(self, attributes: List[str]):\n",
    "        \"\"\"각 행(레코드)에 대한 개인식별가능정보 속성(컬럼)들 사이에 동질 집합을 확인하는 메서드\n",
    "        Pseudonym(dataframe).equivalent_class.keys()를 통해 동질집합 확인\"\"\"\n",
    "        groupby_data = self._dataframe.groupby(attributes)\n",
    "        for group, data in groupby_data:\n",
    "            if len(group) > 1:\n",
    "                key = tuple(group)\n",
    "                # 딕셔너리에서 키 값으로 리스트(동적 타입)는 사용할 수 없으므로 튜플로 변환\n",
    "                self.equivalent_class[key] = data.index.tolist()\n",
    "                # 동질 집합에 해당하는 행(레코드)의 인덱스 번호를 키 값으로 조회되도록 저장\n",
    "                \n",
    "    def countEquivalentClass(self):\n",
    "        for group_key, index_value in self.equivalent_class.items():\n",
    "            print(group_key, len(index_value))\n",
    "            \n",
    "    def addPseudonymizer(self, pseudonymizer):\n",
    "        \"\"\"가명처리 추상 클래스에 대한 자식 클래스를 입력받는 pseudonymizer파라미터를 가지는 메서드\"\"\"\n",
    "        if isinstance(pseudonymizer, Pseudonymizer):\n",
    "            self._pseudonymizers.append(pseudonymizer)\n",
    "        else:\n",
    "            print(\"입력받은 {} 기술은 가명처리 기법에 추가할 수 없습니다.\".format(pseudonymizer))\n",
    "    \n",
    "    def addDictionary(self, column, pseudonymizers):\n",
    "        \"\"\"가명처리를 수행할 데이터 컬럼명과 해당 열에 적용할 여러 가명처리 기법 리스트를 입력받아 다양한 비식별 조치를 수행할 수 있도록 지정하는 메서드\"\"\"\n",
    "        self._pseudonymDictionary[column] = pseudonymizers\n",
    "        \n",
    "    def pseudonymizeData(self):\n",
    "        \"\"\"가명처리 기법을 해당 컬럼에 적용하는 메서드(apply함수를 활용하여 데이터프레임 모든 행, 특정 열에 비식별조치를 취하는 접근방식) \"\"\"\n",
    "        for column, pseudonymizers in self._pseudonymDictionary.items():\n",
    "            for pseudonymizer in pseudonymizers:\n",
    "                if isinstance(pseudonymizer, CategorizationOfColumn):\n",
    "                    self._dataframe[column] = pseudonymizer.pseudonymizeData(self._dataframe[column])\n",
    "                elif isinstance(pseudonymizer, MicroAggregation):\n",
    "                    self._dataframe[column] = pseudonymizer.pseudonymizeData(self._dataframe, column, self.equivalent_class)\n",
    "                else:\n",
    "                    self._dataframe[column] = self._dataframe[column].apply(pseudonymizer.pseudonymizeData)\n",
    "\n",
    "    def getPseudonymizedDataframe(self):\n",
    "        \"\"\"가명처리 데이터 반환\"\"\"\n",
    "        return self._dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b437ad36",
   "metadata": {},
   "outputs": [],
   "source": [
    "PseudonymizeFinanceData = Pseudonym(dataframe = DATA_FINANCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a174cf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(PseudonymizeFinanceData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622456e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "PseudonymizeFinanceData.categorizeEquivalentClass(attributes = [\"HOME_TYPE\", \"TF_LOAN\", \"TF_PENSION\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0891df9a-b2b0-41a6-8730-42a5809adedf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PseudonymizeFinanceData.equivalent_class.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bddaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "PseudonymizeFinanceData.countEquivalentClass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb548543-5820-4118-8d1b-06b85a204ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "PseudonymizeFinanceData.equivalent_class[('비거주용 건물(상가', 'Y', 'Y')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e51be55-40ea-421e-97aa-5b0e4e54a34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "PseudonymizeFinanceData.getPseudonymizedDataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee01e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA_FINANCE.iloc[PseudonymizeFinanceData.equivalent_class[('비거주용 건물(상가', 'Y', 'Y')], :]\n",
    "DATA_FINANCE[\"AMT_CASHADVANCE_PAYMENT\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d27fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FINANCE[DATA_FINANCE[\"AMT_CREDITLOAN\"] > 0] # 94,999명 중 대출실행고객은 9466명"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2f46ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FINANCE.iloc[\n",
    "    PseudonymizeFinanceData.equivalent_class[('비거주용 건물(상가', 'Y', 'Y')], :][\n",
    "    (DATA_FINANCE[\"AMT_CREDITLOAN\"] >= 0) & (DATA_FINANCE[\"AMT_CASHADVANCE_PAYMENT\"] > 8000000)] \n",
    "\n",
    "DATA_FINANCE.iloc[\n",
    "    PseudonymizeFinanceData.equivalent_class[('영업 겸용 단독주택', 'Y', 'Y') ], :][\n",
    "    (DATA_FINANCE[\"AMT_CREDITLOAN\"] >= 0) & (DATA_FINANCE[\"AMT_CASHADVANCE_PAYMENT\"] > 8000000)] \n",
    "\n",
    "# 94,999명 중 대출실행고객은 9466명\n",
    "# ('영업 겸용 단독주택', 'Y', 'Y') ('비거주용 건물(상가', 'Y', 'Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc3379d",
   "metadata": {},
   "source": [
    "7. **가명처리 모듈 활용 예제 스크립트**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c242e8cc",
   "metadata": {},
   "source": [
    "```\n",
    "# ./pseudonymizer/example/example_usage.py\n",
    "\n",
    "from pseudonymizer.pseudonymizer import Pseudonym\n",
    "from pseudonymizer.pseudonymizers.{MODULE.py} import {MODULE}Pseudonymizer\n",
    "\n",
    "\n",
    "# DB 데이터프레임 생성\n",
    "Engine = create_engine(\n",
    "    \"mysql://{user_name}:{password}@localhost/{database}\".format(root, 0123, FINANCIALCONSUMER), \n",
    "    convert_unicode = True)\n",
    "Connection = Engine.connect()\n",
    "\n",
    "DATA = pd.read_sql_table(\"DATA\", Connection)\n",
    "\n",
    "\n",
    "# Pseudonymizer 추상클래스 인스턴스 생성 및 추가\n",
    "{MODULE}_pseudonymizer = {MODULE}Pseudonymizer\n",
    "pseudonym_instance = Pseudonym(dataframe = DATA)\n",
    "\n",
    "# Pseudonymizer의 인스턴스를 입력변수로 설정\n",
    "pseudonym_instance.addPseudonymizer(pseudonymizer = {MODULE}_pseudonymizer)\n",
    "\n",
    "# DATA의 특정 컬럼에 가명처리 기법을 적용하기 위한 Dictionary에 입력\n",
    "pseudonym_instance.addDictionary(column = \"PHONE_NUMBER\", pseudonymizers = [{MODULE}_pseudonymizer])\n",
    "\n",
    "# 가명처리 수행\n",
    "pseudonym_instance.pseudonymizeData()\n",
    "\n",
    "# 가명처리 데이터프레임 반환\n",
    "print(pseudonym_instance.getPseudonymizedDataframe())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0985499b",
   "metadata": {},
   "source": [
    "8. **가명처리 결합**\n",
    "\n",
    "* 결합키(이름, 생년월일, 연락처 등을 활용하여 생성한 암호화된 해시값), 결합키연계정보(결합키가 동일한 정보를 결합할 수 있도록 서로 다른 결합신청자의 결합키를 연계한 정보)\n",
    "\n",
    "\n",
    "* 가명처리시 사용하는 추가정보는 무엇인가요?\n",
    "    - 가명처리에 사용되는 추가정보는 가명 생성 및 복원에 사용되는 정보를 의미합니다. 가명처리 알고리즘 및 방법에 따라 필요한 추가정보는 다를 수 있으며, 이러한 정보가 제3자에게 노출되면 가명처리된 정보를 원래 상태로 되돌릴 수 있으므로 보호가 필요합니다.\n",
    "\n",
    "* 다음은 가명처리에 사용할 수 있는 추가정보의 예시입니다:\n",
    "    - 키(Key): 암호화 및 해시 과정에서 사용되는 키로, 해당 키를 알면 가명처리된 정보를 복호화하거나 원래의 정보로 복원할 수 있습니다.\n",
    "    - 매핑 테이블: 원래의 정보와 가명처리된 정보 간의 대응 관계를 보여주는 테이블로, 이를 통해 가명처리된 정보를 원래의 정보로 매핑할 수 있습니다.\n",
    "    - 알고리즘 세부사항: 가명처리에 사용된 특정 알고리즘의 설정이나 파라미터로, 이러한 세부사항을 알면 원래의 정보를 유추하는 데 도움이 될 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65a5194",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
